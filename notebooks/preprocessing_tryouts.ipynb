{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing & Classification Try-Outs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# | Rank | Classifier | Options | Dataset | Score\n",
    "--- | --- | --- | --- | ---| ---\n",
    "1 |1 |SVM/C | `kernel='rbf', C=1.5, gamma=0.2` | Cleaned+Extended+MinMaxScaled | `0.98541666666666672`\n",
    "2 |1 |SVM/C | `kernel='rbf', C=8.7, gamma=0.04` | Cleaned+Extended+MinMaxScaled | `0.98333333333333328`\n",
    "3 |1 |kNN | `n_neigbors=3` | Cleaned+Extended+MinMaxScaled | `0.98333333333333328`\n",
    "\n",
    "Default options:\n",
    "\n",
    "- Scikit Learn train/test split ratio: `.25`.\n",
    "- Normalizing all columns but `num_holes`.\n",
    "\n",
    "## outdated\n",
    "\n",
    "\\# | Rank | Classifier | Options | Dataset | Score\n",
    "--- | --- | --- | --- | ---| ---\n",
    "1 |1 |SVM/C | `kernel='rbf', C=6.6, gamma=0.35` | Cleaned+MinMaxScaled | `0.978873239436`\n",
    "1 |1 |SVM/C | `kernel='rbf', C=3.9, gamma=0.59` | Cleaned+MinMaxScaled | `0.978873239436`\n",
    "1 |1 |SVM/C | `C=2.0` | Cleaned+MinMaxScaled | `0.973958333333`\n",
    "2 |1 |SVM/C | `C=4.9` | Cleaned+RobustScaled | `0.973958333333`\n",
    "3 |3 |SVM/C | `kernel='rbf', C=3.9` | Cleaned+MinMaxScaled | `0.967391304347`\n",
    "4 |3 |SVM/C | `kernel='sigmoid', C=9.6` | Cleaned+MinMaxScaled | `0.967391304347`\n",
    "5 |5 |RandomForest | `n_estimators=70` | Cleaned | `0.953125000000`\n",
    "6 |5 |RandomForest | `n_estimators=70` | Cleaned+MinMaxScaled | `0.953125000000`\n",
    "7 |5 |SVM/C | `C=2.6` | Cleaned+QuantileTransformed | `0.953125000000`\n",
    "8 |8 |SVM/C | `C=4.3` | Cleaned | `0.947916666667`\n",
    "9 |8 |RandomForest | `n_estimators=16` | Cleaned+RobustScaled | `0.947916666667`\n",
    "10|8 |RandomForest | `n_estimators=32` | Cleaned+QuantileTransformed | `0.947916666667`\n",
    "11|11|RandomForest | `n_estimators=90` | Full | `0.942708333333`\n",
    "12|12|SVM/C | `default` | Full | `0.932291666667`\n",
    "\n",
    "Default options:\n",
    "\n",
    "- RandomForest with `n_estimators=50`, `oob_score=True` and `random_state=123456`.\n",
    "- SVM/C with `kernel=linear`, `C=1.0`.\n",
    "\n",
    "Normalizing all columns but `num_holes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS AND NOTEBOOK SETUP\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>contours</th>\n",
       "      <th>radius</th>\n",
       "      <th>hull_radius</th>\n",
       "      <th>centroid_x</th>\n",
       "      <th>centroid_y</th>\n",
       "      <th>weight_0_0</th>\n",
       "      <th>weight_0_1</th>\n",
       "      <th>weight_0_2</th>\n",
       "      <th>weight_0_3</th>\n",
       "      <th>...</th>\n",
       "      <th>weight_2_0</th>\n",
       "      <th>weight_2_1</th>\n",
       "      <th>weight_2_2</th>\n",
       "      <th>weight_2_3</th>\n",
       "      <th>weight_3_0</th>\n",
       "      <th>weight_3_1</th>\n",
       "      <th>weight_3_2</th>\n",
       "      <th>weight_3_3</th>\n",
       "      <th>num_holes</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>291.653385</td>\n",
       "      <td>44.952083</td>\n",
       "      <td>10.493405</td>\n",
       "      <td>13.664167</td>\n",
       "      <td>15.859298</td>\n",
       "      <td>15.380416</td>\n",
       "      <td>2.320312</td>\n",
       "      <td>42.125000</td>\n",
       "      <td>38.457292</td>\n",
       "      <td>4.064063</td>\n",
       "      <td>...</td>\n",
       "      <td>3.515104</td>\n",
       "      <td>31.285937</td>\n",
       "      <td>36.993750</td>\n",
       "      <td>6.548958</td>\n",
       "      <td>1.218229</td>\n",
       "      <td>37.840625</td>\n",
       "      <td>39.710417</td>\n",
       "      <td>6.739583</td>\n",
       "      <td>0.379688</td>\n",
       "      <td>4.532813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>67.428881</td>\n",
       "      <td>8.744703</td>\n",
       "      <td>0.889372</td>\n",
       "      <td>0.814930</td>\n",
       "      <td>1.193617</td>\n",
       "      <td>1.869070</td>\n",
       "      <td>3.623932</td>\n",
       "      <td>13.615466</td>\n",
       "      <td>15.544662</td>\n",
       "      <td>8.440119</td>\n",
       "      <td>...</td>\n",
       "      <td>5.690358</td>\n",
       "      <td>19.265783</td>\n",
       "      <td>14.245519</td>\n",
       "      <td>6.925247</td>\n",
       "      <td>2.723832</td>\n",
       "      <td>14.236761</td>\n",
       "      <td>16.414749</td>\n",
       "      <td>9.965595</td>\n",
       "      <td>0.584767</td>\n",
       "      <td>2.868122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>153.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>8.303587</td>\n",
       "      <td>11.549360</td>\n",
       "      <td>11.835737</td>\n",
       "      <td>10.582800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>244.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>9.822737</td>\n",
       "      <td>13.067626</td>\n",
       "      <td>15.077516</td>\n",
       "      <td>14.116460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>275.500000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>10.369215</td>\n",
       "      <td>13.617666</td>\n",
       "      <td>15.797984</td>\n",
       "      <td>15.295089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>326.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>11.043633</td>\n",
       "      <td>14.191667</td>\n",
       "      <td>16.571982</td>\n",
       "      <td>16.354908</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>512.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>13.117590</td>\n",
       "      <td>16.446964</td>\n",
       "      <td>20.410788</td>\n",
       "      <td>20.841542</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              area     contours       radius  hull_radius   centroid_x  \\\n",
       "count  1920.000000  1920.000000  1920.000000  1920.000000  1920.000000   \n",
       "mean    291.653385    44.952083    10.493405    13.664167    15.859298   \n",
       "std      67.428881     8.744703     0.889372     0.814930     1.193617   \n",
       "min     153.000000    20.000000     8.303587    11.549360    11.835737   \n",
       "25%     244.000000    39.000000     9.822737    13.067626    15.077516   \n",
       "50%     275.500000    44.000000    10.369215    13.617666    15.797984   \n",
       "75%     326.000000    51.000000    11.043633    14.191667    16.571982   \n",
       "max     512.000000    88.000000    13.117590    16.446964    20.410788   \n",
       "\n",
       "        centroid_y   weight_0_0   weight_0_1   weight_0_2   weight_0_3  \\\n",
       "count  1920.000000  1920.000000  1920.000000  1920.000000  1920.000000   \n",
       "mean     15.380416     2.320312    42.125000    38.457292     4.064063   \n",
       "std       1.869070     3.623932    13.615466    15.544662     8.440119   \n",
       "min      10.582800     0.000000     0.000000     0.000000     0.000000   \n",
       "25%      14.116460     0.000000    36.000000    29.000000     0.000000   \n",
       "50%      15.295089     0.000000    45.000000    40.000000     0.000000   \n",
       "75%      16.354908     4.000000    52.000000    50.000000     4.000000   \n",
       "max      20.841542    22.000000    64.000000    64.000000    62.000000   \n",
       "\n",
       "          ...        weight_2_0   weight_2_1   weight_2_2   weight_2_3  \\\n",
       "count     ...       1920.000000  1920.000000  1920.000000  1920.000000   \n",
       "mean      ...          3.515104    31.285937    36.993750     6.548958   \n",
       "std       ...          5.690358    19.265783    14.245519     6.925247   \n",
       "min       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "25%       ...          0.000000    15.000000    28.000000     0.000000   \n",
       "50%       ...          0.000000    32.000000    38.000000     5.000000   \n",
       "75%       ...          6.000000    48.000000    47.000000    11.000000   \n",
       "max       ...         39.000000    64.000000    64.000000    31.000000   \n",
       "\n",
       "        weight_3_0   weight_3_1   weight_3_2   weight_3_3    num_holes  \\\n",
       "count  1920.000000  1920.000000  1920.000000  1920.000000  1920.000000   \n",
       "mean      1.218229    37.840625    39.710417     6.739583     0.379688   \n",
       "std       2.723832    14.236761    16.414749     9.965595     0.584767   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000    31.000000    33.000000     0.000000     0.000000   \n",
       "50%       0.000000    40.000000    44.000000     2.000000     0.000000   \n",
       "75%       1.000000    47.000000    51.000000    10.000000     1.000000   \n",
       "max      29.000000    64.000000    64.000000    55.000000     2.000000   \n",
       "\n",
       "             label  \n",
       "count  1920.000000  \n",
       "mean      4.532813  \n",
       "std       2.868122  \n",
       "min       0.000000  \n",
       "25%       2.000000  \n",
       "50%       5.000000  \n",
       "75%       7.000000  \n",
       "max       9.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMPORTING OUR DATASET\n",
    "data_full = pd.read_csv('../dataset-numpy/dataset.csv')\n",
    "data_clean_manual = pd.read_csv('../dataset-numpy/dataset-clean-manual.csv')\n",
    "data_ext_clean_manual = pd.read_csv('../dataset-numpy/dataset-extended-clean-manual.csv')\n",
    "data_clean_manual.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['area', 'contours', 'radius', 'hull_radius', 'centroid_x', 'centroid_y']\n",
    "columns_ext = columns[:] # copy\n",
    "COUNT = 8\n",
    "for x in range(COUNT):\n",
    "    for y in range(COUNT):\n",
    "        name = '_'.join(['weight', str(x), str(y)])\n",
    "        columns_ext.append(name)\n",
    "        if x < 4 and y < 4:\n",
    "            columns.append(name)\n",
    "        \n",
    "def scale(data, scaler, columns):\n",
    "    return pd.DataFrame(scaler.fit_transform(data[columns]), columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 24) (1920, 72)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "minmaxscaled = data_clean_manual.copy()\n",
    "minmaxscaled[columns] = scale(data_clean_manual, MinMaxScaler(), columns)\n",
    "\n",
    "minmaxscaled_ext = data_ext_clean_manual.copy()\n",
    "minmaxscaled_ext[columns_ext] = scale(data_ext_clean_manual, MinMaxScaler(), columns_ext)\n",
    "\n",
    "print minmaxscaled.shape, minmaxscaled_ext.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "robustscaled = data_clean_manual.copy()\n",
    "robustscaled[columns] = scale(data_clean_manual, RobustScaler(), columns)\n",
    "robustscaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "quantiletransformed = data_clean_manual.copy()\n",
    "quantiletransformed[columns] = scale(data_clean_manual, QuantileTransformer(), columns)\n",
    "quantiletransformed.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, split, validation):\n",
    "    border = int(len(data) * split)\n",
    "    train_data = data[:border]\n",
    "    test_data = data[border:]\n",
    "\n",
    "    assert len(train_data) + len(test_data) == len(data), \"Invalid split!\"\n",
    "\n",
    "    X_train = train_data.iloc[:,:-1]\n",
    "    Y_train = train_data.iloc[:,-1]\n",
    "\n",
    "    X_test = test_data.iloc[validation:,:-1]\n",
    "    Y_test = test_data.iloc[validation:,-1]\n",
    "    \n",
    "    X_validate = test_data.iloc[:validation,:-1]\n",
    "    Y_validate = test_data.iloc[:validation,-1]\n",
    "    return X_train, Y_train, X_test, Y_test, X_validate, Y_validate\n",
    "\n",
    "X_train, Y_train, X_test, Y_test, X_validate, Y_validate = split_data(minmaxscaled_ext, .2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = minmaxscaled_ext\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data.iloc[:,:-1], data.iloc[:,-1], test_size=.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM FOREST\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "top_rf = (2, 0.0)\n",
    "for n_e in range(2, 101):\n",
    "    rf = RandomForestClassifier(n_estimators=n_e, oob_score=True, random_state=123456)\n",
    "    rf.fit(X_train, Y_train)\n",
    "    score = rf.score(X_test, Y_test)\n",
    "    if score > top_rf[1]:\n",
    "        top_rf = (n_e, score)\n",
    "        print('N_E:', n_e, 'Score:', score)\n",
    "print('Top:', top_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Score:', 0.98541666666666672)\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn import svm\n",
    "\n",
    "svc = svm.SVC(kernel='rbf', C=1.5, gamma=.2)\n",
    "svc.fit(X_train, Y_train)\n",
    "print('Score:', svc.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting some validation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_validate)):\n",
    "    sample = np.array(X_validate.iloc[i,:], dtype=pd.Series).reshape(1, -1)\n",
    "    label = Y_validate.iloc[i]\n",
    "    prediction = svc.predict(sample)[0]\n",
    "    print('prediction:', prediction, '== label', label, ':', prediction == label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the optimal C value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Cs = np.arange(.1, 10, 0.1)\n",
    "scores = np.zeros((len(Cs)))\n",
    "index = 0\n",
    "top = (.1, 0)\n",
    "for c in Cs:\n",
    "    print('%d / %d' % (index, len(Cs)-1))\n",
    "    svc = svm.SVC(kernel='linear', C=c)\n",
    "    svc.fit(X_train, Y_train)\n",
    "    score = svc.score(X_test, Y_test)\n",
    "    scores[index] = score\n",
    "    if score > top[1]:\n",
    "        top = (c, score)\n",
    "    index += 1\n",
    "\n",
    "print('Top:', top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Max:', scores.max())\n",
    "plt.plot(Cs, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the optimal gamma for RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Gs = np.arange(.1, 4, .1)\n",
    "Cs = np.arange(.1, 10, .1)\n",
    "\n",
    "steps = len(Gs) * len(Cs)\n",
    "scores = np.zeros((steps))\n",
    "index = 0\n",
    "top = (.1, .01, 0)\n",
    "\n",
    "for g in Gs:\n",
    "    for c in Cs:\n",
    "        print('%d / %d' % (index, steps))\n",
    "        svc = svm.SVC(kernel='rbf', C=c, gamma=g)\n",
    "        svc.fit(X_train, Y_train)\n",
    "        score = svc.score(X_test, Y_test)\n",
    "        scores[index] = score\n",
    "        if score > top[2]:\n",
    "            top = (c, g, score)\n",
    "        index += 1\n",
    "\n",
    "print('Top:', top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "sgd = linear_model.SGDClassifier(max_iter=1000)\n",
    "sgd.fit(X_train, Y_train)\n",
    "score = sgd.score(X_test, Y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, Y_train)\n",
    "score = knn.score(X_test, Y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Ns = range(3, 30)\n",
    "scores = np.zeros((len(Ns)))\n",
    "index = 0\n",
    "top = (3, 0)\n",
    "for n in Ns:\n",
    "    print('%d / %d (%d)' % (index, len(Ns)-1, n))\n",
    "    knn = KNeighborsClassifier(n_neighbors=n)\n",
    "    knn.fit(X_train, Y_train)\n",
    "    score = knn.score(X_test, Y_test)\n",
    "    scores[index] = score\n",
    "    if score > top[1]:\n",
    "        top = (n, score)\n",
    "    index += 1\n",
    "\n",
    "print('Top:', top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Automation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "datasets = [\n",
    "    ('Cleaned+MinMaxScaled', minmaxscaled),\n",
    "    ('Cleaned+Extended+MinMaxScaled', minmaxscaled_ext)\n",
    "]\n",
    "\n",
    "options = {\n",
    "    'AdaBoost': {\n",
    "        'base_estimator': [\n",
    "            svm.SVC(kernel='rbf', C=8.7, gamma=0.04),\n",
    "            RandomForestClassifier(n_estimators=69)\n",
    "        ],\n",
    "        'algorithm': ['SAMME']\n",
    "    },\n",
    "    'SVM/C': {\n",
    "        'kernel': ('linear', 'rbf'),\n",
    "        'C': np.arange(.1, 12.0, .2),\n",
    "        'gamma': [.001, .005, .01, .025, .05, .075, .1, .25, .5, 1, 3, 5, 8]\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'n_estimators': range(10, 70)\n",
    "    }\n",
    "}\n",
    "\n",
    "classifiers = [\n",
    "#     ('AdaBoost', AdaBoostClassifier),\n",
    "    ('SVM/C', svm.SVC),\n",
    "#     ('RandomForest', RandomForestClassifier)\n",
    "]\n",
    "\n",
    "def search(classifiers, options, datasets, test_size, random_state):\n",
    "    results = {\n",
    "        'rank': [],\n",
    "        'classifier': [],\n",
    "        'options': [],\n",
    "        'dataset': [],\n",
    "        'score': []\n",
    "    }\n",
    "\n",
    "    for dataset in datasets:\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(dataset[1].iloc[:,:-1], dataset[1].iloc[:,-1],\\\n",
    "                                                            test_size=test_size, random_state=random_state)\n",
    "        \n",
    "        for classifier in classifiers:\n",
    "            name = classifier[0]\n",
    "            print 'Testing', dataset[0], 'on', name, '...'\n",
    "\n",
    "            model = GridSearchCV(classifier[1](), options[name], verbose=1, cv=3)\n",
    "            model.fit(X_train, Y_train)\n",
    "            \n",
    "            print 'Params:', model.best_params_\n",
    "            print 'MSE:', model.best_score_\n",
    "            print\n",
    "            \n",
    "            results['rank'].append(0)\n",
    "            results['classifier'].append(name)\n",
    "            results['options'].append(str(model.best_params_))\n",
    "            results['dataset'].append(dataset[0])\n",
    "            results['score'].append(model.best_score_)\n",
    "            \n",
    "    return results\n",
    "\n",
    "results = search(classifiers, options, datasets, .35, 123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results).sort_values(['score'], ascending=[False])\n",
    "results_df['rank'] = pd.Series(range(1, len(results_df) + 1), index=results_df.index)\n",
    "results_df[['rank', 'classifier', 'options', 'dataset', 'score']].to_csv('../classifiers/results_testsize35.csv', sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy', 0.97499999999999998)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "best = svm.SVC(kernel='rbf', C=1.5, gamma=0.2)\n",
    "\n",
    "Y_pred = best.fit(X_train, Y_train).predict(X_test)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes):\n",
    "#     print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "\n",
    "print('Accuracy', best.score(X_test, Y_test))\n",
    "plot_confusion_matrix(cnf_matrix, classes=range(0,10))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
