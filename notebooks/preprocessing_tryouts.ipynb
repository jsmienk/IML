{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing & Classification Try-Outs\n",
    "\n",
    "## Datasets\n",
    "\n",
    "- ~~Full~~\n",
    "- ~~Cleaned~~\n",
    "- ~~Cleaned+MinMaxScaled~~\n",
    "- ~~Cleaned+RobustScaled~~\n",
    "- ~~Cleaned+QuantileTransformed~~\n",
    "- Cleaned+Extended+MinMaxScaled\n",
    "- Cleaned+CleanExtended+MinMaxScaled\n",
    "- v4 (?)\n",
    "- v5 (mixed with MNIST digits)\n",
    "- v6 (Automatic Feature Selection)\n",
    "\n",
    "## Classifiers\n",
    "\n",
    "- ~~RandomForest~~\n",
    "- SVM/C\n",
    "- kNN\n",
    "- ~~SGD~~\n",
    "\n",
    "## Winner\n",
    "\n",
    "SVM/C `kernel='rbf', C=3.8, gamma=0.1` with v6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS AND NOTEBOOK SETUP\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# | Rank | Classifier | Options | Dataset | Score\n",
    "--- | --- | --- | --- | ---| ---\n",
    "1 |1 |SVM/C | `kernel='rbf', C=1.5, gamma=0.2` | Cleaned+Extended+MinMaxScaled | `0.98541666666666672`\n",
    "2 |1 |SVM/C | `kernel='rbf', C=8.7, gamma=0.04` | Cleaned+Extended+MinMaxScaled | `0.98333333333333328`\n",
    "3 |1 |kNN | `n_neigbors=3` | Cleaned+Extended+MinMaxScaled | `0.98333333333333328`\n",
    "4 |1 |SVM/C | `kernel='rbf', C=3.0, gamma=0.2` | Cleaned+CleanExtended+MinMaxScaled | `0.97916666666666663`\n",
    "\n",
    "Default options:\n",
    "\n",
    "- Scikit Learn train/test split ratio: `.25`.\n",
    "- Normalizing all columns but `num_holes`.\n",
    "\n",
    "## outdated\n",
    "\n",
    "\\# | Rank | Classifier | Options | Dataset | Score\n",
    "--- | --- | --- | --- | ---| ---\n",
    "1 |1 |SVM/C | `kernel='rbf', C=6.6, gamma=0.35` | Cleaned+MinMaxScaled | `0.978873239436`\n",
    "1 |1 |SVM/C | `kernel='rbf', C=3.9, gamma=0.59` | Cleaned+MinMaxScaled | `0.978873239436`\n",
    "1 |1 |SVM/C | `C=2.0` | Cleaned+MinMaxScaled | `0.973958333333`\n",
    "2 |1 |SVM/C | `C=4.9` | Cleaned+RobustScaled | `0.973958333333`\n",
    "3 |3 |SVM/C | `kernel='rbf', C=3.9` | Cleaned+MinMaxScaled | `0.967391304347`\n",
    "4 |3 |SVM/C | `kernel='sigmoid', C=9.6` | Cleaned+MinMaxScaled | `0.967391304347`\n",
    "5 |5 |RandomForest | `n_estimators=70` | Cleaned | `0.953125000000`\n",
    "6 |5 |RandomForest | `n_estimators=70` | Cleaned+MinMaxScaled | `0.953125000000`\n",
    "7 |5 |SVM/C | `C=2.6` | Cleaned+QuantileTransformed | `0.953125000000`\n",
    "8 |8 |SVM/C | `C=4.3` | Cleaned | `0.947916666667`\n",
    "9 |8 |RandomForest | `n_estimators=16` | Cleaned+RobustScaled | `0.947916666667`\n",
    "10|8 |RandomForest | `n_estimators=32` | Cleaned+QuantileTransformed | `0.947916666667`\n",
    "11|11|RandomForest | `n_estimators=90` | Full | `0.942708333333`\n",
    "12|12|SVM/C | `default` | Full | `0.932291666667`\n",
    "\n",
    "Default options:\n",
    "\n",
    "- RandomForest with `n_estimators=50`, `oob_score=True` and `random_state=123456`.\n",
    "- SVM/C with `kernel=linear`, `C=1.0`.\n",
    "\n",
    "Normalizing all columns but `num_holes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'area', u'contours', u'radius', u'hull_radius', u'centroid_x',\n",
       "       u'centroid_y', u'weight_0_0', u'weight_0_1', u'weight_0_2',\n",
       "       u'weight_0_3', u'weight_0_4', u'weight_0_5', u'weight_0_6',\n",
       "       u'weight_0_7', u'weight_1_0', u'weight_1_1', u'weight_1_2',\n",
       "       u'weight_1_3', u'weight_1_4', u'weight_1_5', u'weight_1_6',\n",
       "       u'weight_1_7', u'weight_2_0', u'weight_2_1', u'weight_2_2',\n",
       "       u'weight_2_3', u'weight_2_4', u'weight_2_5', u'weight_2_6',\n",
       "       u'weight_2_7', u'weight_3_0', u'weight_3_1', u'weight_3_2',\n",
       "       u'weight_3_3', u'weight_3_4', u'weight_3_5', u'weight_3_6',\n",
       "       u'weight_3_7', u'weight_4_0', u'weight_4_1', u'weight_4_2',\n",
       "       u'weight_4_3', u'weight_4_4', u'weight_4_5', u'weight_4_6',\n",
       "       u'weight_4_7', u'weight_5_0', u'weight_5_1', u'weight_5_2',\n",
       "       u'weight_5_3', u'weight_5_4', u'weight_5_5', u'weight_5_6',\n",
       "       u'weight_5_7', u'weight_6_0', u'weight_6_1', u'weight_6_2',\n",
       "       u'weight_6_3', u'weight_6_4', u'weight_6_5', u'weight_6_6',\n",
       "       u'weight_6_7', u'weight_7_0', u'weight_7_1', u'weight_7_2',\n",
       "       u'weight_7_3', u'weight_7_4', u'weight_7_5', u'weight_7_6',\n",
       "       u'weight_7_7', u'num_holes', u'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMPORTING OUR DATASET\n",
    "data_full = pd.read_csv('../dataset-numpy/dataset.csv')\n",
    "data_clean_manual = pd.read_csv('../dataset-numpy/dataset-clean-manual.csv')\n",
    "data_ext_clean_manual = pd.read_csv('../dataset-numpy/dataset-extended-clean-manual.csv')\n",
    "data_v4 = pd.read_csv('../dataset-numpy/dataset-v4.csv')\n",
    "data_v6 = pd.read_csv('../dataset-numpy/dataset-v6.csv')\n",
    "\n",
    "data_ext_clean_manual.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "less_columns = data_clean_manual.columns.values\n",
    "columns_v4 = data_v4.columns.values\n",
    "columns_v6 = data_v6.columns.values\n",
    "columns_to_not_normalize = ['num_holes', 'label']\n",
    "\n",
    "columns_v4_to_normalize = [c for c in columns_v4 if not c in columns_to_not_normalize]\n",
    "columns_v6_to_normalize = [c for c in columns_v6 if not c in columns_to_not_normalize]\n",
    "less_columns_to_normalize = [c for c in less_columns if not c in columns_to_not_normalize]\n",
    "        \n",
    "def scale(data, scaler, columns):\n",
    "    return pd.DataFrame(scaler.fit_transform(data[columns]), columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 24) (1920, 72) (1920, 60) (1920, 56)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>contours</th>\n",
       "      <th>radius</th>\n",
       "      <th>hull_radius</th>\n",
       "      <th>centroid_x</th>\n",
       "      <th>centroid_y</th>\n",
       "      <th>angle</th>\n",
       "      <th>weight_0_2</th>\n",
       "      <th>weight_0_3</th>\n",
       "      <th>weight_0_4</th>\n",
       "      <th>...</th>\n",
       "      <th>weight_6_5</th>\n",
       "      <th>weight_6_6</th>\n",
       "      <th>weight_7_2</th>\n",
       "      <th>weight_7_3</th>\n",
       "      <th>weight_7_4</th>\n",
       "      <th>weight_7_5</th>\n",
       "      <th>weight_7_6</th>\n",
       "      <th>weight_7_7</th>\n",
       "      <th>num_holes</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.386221</td>\n",
       "      <td>0.366942</td>\n",
       "      <td>0.454885</td>\n",
       "      <td>0.431804</td>\n",
       "      <td>0.469217</td>\n",
       "      <td>0.467661</td>\n",
       "      <td>0.779948</td>\n",
       "      <td>0.393815</td>\n",
       "      <td>0.817187</td>\n",
       "      <td>0.787565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.591960</td>\n",
       "      <td>0.240299</td>\n",
       "      <td>0.412956</td>\n",
       "      <td>0.813086</td>\n",
       "      <td>0.781217</td>\n",
       "      <td>0.472656</td>\n",
       "      <td>0.151497</td>\n",
       "      <td>0.018034</td>\n",
       "      <td>0.379688</td>\n",
       "      <td>4.532813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.187824</td>\n",
       "      <td>0.128599</td>\n",
       "      <td>0.184747</td>\n",
       "      <td>0.166394</td>\n",
       "      <td>0.139196</td>\n",
       "      <td>0.182193</td>\n",
       "      <td>0.368169</td>\n",
       "      <td>0.333569</td>\n",
       "      <td>0.281508</td>\n",
       "      <td>0.296906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375565</td>\n",
       "      <td>0.315142</td>\n",
       "      <td>0.342576</td>\n",
       "      <td>0.284703</td>\n",
       "      <td>0.331414</td>\n",
       "      <td>0.403487</td>\n",
       "      <td>0.284578</td>\n",
       "      <td>0.096219</td>\n",
       "      <td>0.584767</td>\n",
       "      <td>2.868122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.253482</td>\n",
       "      <td>0.279412</td>\n",
       "      <td>0.315569</td>\n",
       "      <td>0.310002</td>\n",
       "      <td>0.378048</td>\n",
       "      <td>0.344453</td>\n",
       "      <td>0.863493</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.341226</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.429087</td>\n",
       "      <td>0.422310</td>\n",
       "      <td>0.462067</td>\n",
       "      <td>0.459344</td>\n",
       "      <td>0.973220</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.481894</td>\n",
       "      <td>0.455882</td>\n",
       "      <td>0.569182</td>\n",
       "      <td>0.539510</td>\n",
       "      <td>0.552328</td>\n",
       "      <td>0.562653</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              area     contours       radius  hull_radius   centroid_x  \\\n",
       "count  1920.000000  1920.000000  1920.000000  1920.000000  1920.000000   \n",
       "mean      0.386221     0.366942     0.454885     0.431804     0.469217   \n",
       "std       0.187824     0.128599     0.184747     0.166394     0.139196   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.253482     0.279412     0.315569     0.310002     0.378048   \n",
       "50%       0.341226     0.352941     0.429087     0.422310     0.462067   \n",
       "75%       0.481894     0.455882     0.569182     0.539510     0.552328   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        centroid_y        angle   weight_0_2   weight_0_3   weight_0_4  \\\n",
       "count  1920.000000  1920.000000  1920.000000  1920.000000  1920.000000   \n",
       "mean      0.467661     0.779948     0.393815     0.817187     0.787565   \n",
       "std       0.182193     0.368169     0.333569     0.281508     0.296906   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.344453     0.863493     0.062500     0.750000     0.625000   \n",
       "50%       0.459344     0.973220     0.375000     1.000000     1.000000   \n",
       "75%       0.562653     1.000000     0.687500     1.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "          ...        weight_6_5   weight_6_6   weight_7_2   weight_7_3  \\\n",
       "count     ...       1920.000000  1920.000000  1920.000000  1920.000000   \n",
       "mean      ...          0.591960     0.240299     0.412956     0.813086   \n",
       "std       ...          0.375565     0.315142     0.342576     0.284703   \n",
       "min       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "25%       ...          0.250000     0.000000     0.062500     0.750000   \n",
       "50%       ...          0.750000     0.062500     0.375000     1.000000   \n",
       "75%       ...          0.937500     0.437500     0.703125     1.000000   \n",
       "max       ...          1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        weight_7_4   weight_7_5   weight_7_6   weight_7_7    num_holes  \\\n",
       "count  1920.000000  1920.000000  1920.000000  1920.000000  1920.000000   \n",
       "mean      0.781217     0.472656     0.151497     0.018034     0.379688   \n",
       "std       0.331414     0.403487     0.284578     0.096219     0.584767   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.625000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       1.000000     0.437500     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     0.875000     0.125000     0.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     2.000000   \n",
       "\n",
       "             label  \n",
       "count  1920.000000  \n",
       "mean      4.532813  \n",
       "std       2.868122  \n",
       "min       0.000000  \n",
       "25%       2.000000  \n",
       "50%       5.000000  \n",
       "75%       7.000000  \n",
       "max       9.000000  \n",
       "\n",
       "[8 rows x 56 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "minmaxscaled = data_clean_manual.copy()\n",
    "minmaxscaled[less_columns_to_normalize] = scale(data_clean_manual, MinMaxScaler(), less_columns_to_normalize)\n",
    "\n",
    "minmaxscaled_ext = data_ext_clean_manual.copy()\n",
    "minmaxscaled_ext[columns_v4_to_normalize] = scale(data_ext_clean_manual, MinMaxScaler(), columns_v4_to_normalize)\n",
    "\n",
    "scaled_v4 = data_v4.copy()\n",
    "scaled_v4[columns_v4_to_normalize] = scale(data_v4, MinMaxScaler(), columns_v4_to_normalize)\n",
    "\n",
    "scaled_v6 = data_v6.copy()\n",
    "scaled_v6[columns_v6_to_normalize] = scale(data_v6, MinMaxScaler(), columns_v6_to_normalize)\n",
    "\n",
    "print minmaxscaled.shape, minmaxscaled_ext.shape, scaled_v4.shape, scaled_v6.shape\n",
    "scaled_v6.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ~~RobustScaler~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "robustscaled = data_clean_manual.copy()\n",
    "robustscaled[columns] = scale(data_clean_manual, RobustScaler(), columns)\n",
    "robustscaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ~~QuantileTransformer~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "quantiletransformed = data_clean_manual.copy()\n",
    "quantiletransformed[columns] = scale(data_clean_manual, QuantileTransformer(), columns)\n",
    "quantiletransformed.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split(data, ratio):\n",
    "    return train_test_split(data.iloc[:,:-1], data.iloc[:,-1], test_size=ratio)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = split(scaled_v6, .25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('N_E:', 2, 'Score:', 0.8041666666666667)\n",
      "('N_E:', 3, 'Score:', 0.88541666666666663)\n",
      "('N_E:', 4, 'Score:', 0.91249999999999998)\n",
      "('N_E:', 6, 'Score:', 0.94166666666666665)\n",
      "('N_E:', 7, 'Score:', 0.94374999999999998)\n",
      "('N_E:', 8, 'Score:', 0.9458333333333333)\n",
      "('N_E:', 9, 'Score:', 0.94999999999999996)\n",
      "('N_E:', 11, 'Score:', 0.95625000000000004)\n",
      "('N_E:', 14, 'Score:', 0.95833333333333337)\n",
      "('N_E:', 15, 'Score:', 0.9604166666666667)\n",
      "('N_E:', 16, 'Score:', 0.96458333333333335)\n",
      "('N_E:', 17, 'Score:', 0.96875)\n",
      "('N_E:', 22, 'Score:', 0.97083333333333333)\n",
      "('N_E:', 24, 'Score:', 0.97291666666666665)\n",
      "('N_E:', 46, 'Score:', 0.97499999999999998)\n",
      "('N_E:', 62, 'Score:', 0.9770833333333333)\n",
      "('N_E:', 81, 'Score:', 0.97916666666666663)\n",
      "('Top:', (81, 0.97916666666666663))\n"
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "top_rf = (2, 0.0)\n",
    "for n_e in range(2, 101):\n",
    "    rf = RandomForestClassifier(n_estimators=n_e, oob_score=True, random_state=123456)\n",
    "    rf.fit(X_train, Y_train)\n",
    "    score = rf.score(X_test, Y_test)\n",
    "    if score > top_rf[1]:\n",
    "        top_rf = (n_e, score)\n",
    "        print('N_E:', n_e, 'Score:', score)\n",
    "print('Top:', top_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Support Vector Machine\n",
    "\n",
    "100 x random train test split:\n",
    "\n",
    "\\# | Dataset | Options | Min | Max | Mean | Variance\n",
    "---| --- | --- | --- | --- | --- | ---\n",
    "1 | v6 | `kernel='rbf', C=3.8, gamma=0.1` | `0.9531250000` | `1.0000000000` | `0.9841666666` | `0.031041666`\n",
    "1 | Cleaned+Extended+MinMaxScaled | `kernel='rbf', C=1.5, gamma=0.2` | `0.9708333333` | `0.9937500000` | `0.9837291666` | `0.022916667`\n",
    "2 | ~~Cleaned+CleanExtended+MinMaxScaled~~ | `kernel='rbf', C=3.0, gamma=0.2` | `0.9687500000` | `0.9958333333` | `0.9814791666` | `0.027083333`\n",
    "3 | Cleaned+Extended+MinMaxScaled | `kernel='linear', C=1.1` | `0.9604166666` | `0.9916666666` | `0.9743750000`\n",
    "4 | Cleaned+MinMaxScaled | `kernel='rbf', C=6.6, gamma=0.35` | `0.9500000000` | `0.9833333333` | `0.9712708333`\n",
    "5 | ~~Cleaned+CleanExtended+MinMaxScaled~~ | `kernel='linear', C=0.4` | `0.9437500000` | `0.9875000000` | `0.9702708333`\n",
    "6 | Cleaned+MinMaxScaled | `kernel='linear', C=1.5` | `0.9395833333` | `0.9812500000` | `0.9626250000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Score: 0.953125\n",
      "Max Score: 1.0\n",
      "Mean Score: 0.984166666667\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn import svm\n",
    "\n",
    "ITERS = 300\n",
    "scores = np.zeros((ITERS))\n",
    "for i in range(ITERS):\n",
    "#     print i, '/', ITERS - 1\n",
    "    X_train, X_test, Y_train, Y_test = split(scaled_v6, .1)\n",
    "    svc = svm.SVC(kernel='rbf', C=3.8, gamma=0.1)\n",
    "    svc.fit(X_train, Y_train)\n",
    "    scores[i] = svc.score(X_test, Y_test)\n",
    "    \n",
    "print 'Min Score:', scores.min()\n",
    "print 'Max Score:', scores.max()\n",
    "print 'Mean Score:', scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compared Datasets with Same Options\n",
    "\n",
    "300 Iterations of 25% splits.\n",
    "\n",
    "Options: `kernel='rbf', C=2.8, gamma=0.1`\n",
    "\n",
    "Options: `kernel='rbf', C=3.0, gamma=0.2`\n",
    "\n",
    "\\# | Dataset | Min Score | Mean Score | Max Score\n",
    "---| --- | --- | --- | ---\n",
    "1| v4 | `0.96458333` | `0.98163194`| `0.99583333`\n",
    "2| Cleaned+MinMaxScaled+Extended | `0.96041666` | `0.98059722` | `0.99583333`\n",
    "3| Cleaned+MinMaxScaled | `0.94791666` | `0.96754861` | `0.98541666`\n",
    "\n",
    "Options: `kernel='rbf', C=1.5, gamma=0.2`\n",
    "\n",
    "\\# | Dataset | Min Score | Mean Score | Max Score\n",
    "---| --- | --- | --- | ---\n",
    "1| v4 | `0.96666666` | `0.98113888`| `0.99583333`\n",
    "2| Cleaned+MinMaxScaled+Extended | `0.96041666` | `0.97952083` | `0.99375000`\n",
    "3| Cleaned+MinMaxScaled | `0.93750000` | `0.95971527` | `0.98125000`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1728, 55) (192, 55) (1728,) (192,)\n"
     ]
    }
   ],
   "source": [
    "DATASET = scaled_v6\n",
    "X_train_test, X_validation, Y_train_test, Y_validation = split(DATASET, .1)\n",
    "\n",
    "print X_train_test.shape, X_validation.shape, Y_train_test.shape, Y_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score  0 : 0.973988439306\n",
      "Score  1 : 0.991329479769\n",
      "Score  2 : 0.982658959538\n",
      "Score  3 : 0.985549132948\n",
      "Score  4 : 0.988439306358\n",
      "Score  5 : 0.982658959538\n",
      "Score  6 : 0.979768786127\n",
      "Score  7 : 0.982658959538\n",
      "Score  8 : 0.994219653179\n",
      "Score  9 : 0.979768786127\n",
      "\n",
      "Score:  0.984375\n"
     ]
    }
   ],
   "source": [
    "# Testing on train/test data\n",
    "svc = svm.SVC(kernel='rbf', C=3.8, gamma=0.2)\n",
    "\n",
    "FOLDS = 10\n",
    "for i in range(FOLDS):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_train_test, Y_train_test, test_size=.20)\n",
    "    svc.fit(X_train, Y_train)\n",
    "    print 'Score ', i, ':', svc.score(X_test, Y_test)\n",
    "\n",
    "print\n",
    "# Validating on unseen validation data\n",
    "print 'Score: ', svc.score(X_validation, Y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the optimal C and Gamma for RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 3861\n",
      "1 / 3861\n",
      "2 / 3861\n",
      "3 / 3861\n",
      "4 / 3861\n",
      "5 / 3861\n",
      "6 / 3861\n",
      "7 / 3861\n",
      "8 / 3861\n",
      "9 / 3861\n",
      "10 / 3861\n",
      "11 / 3861\n",
      "12 / 3861\n",
      "13 / 3861\n",
      "14 / 3861\n",
      "15 / 3861\n",
      "16 / 3861\n",
      "17 / 3861\n",
      "18 / 3861\n",
      "19 / 3861\n",
      "20 / 3861\n",
      "21 / 3861\n",
      "22 / 3861\n",
      "23 / 3861\n",
      "24 / 3861\n",
      "25 / 3861\n",
      "26 / 3861\n",
      "27 / 3861\n",
      "28 / 3861\n",
      "29 / 3861\n",
      "30 / 3861\n",
      "31 / 3861\n",
      "32 / 3861\n",
      "33 / 3861\n",
      "34 / 3861\n",
      "35 / 3861\n",
      "36 / 3861\n",
      "37 / 3861\n",
      "38 / 3861\n",
      "39 / 3861\n",
      "40 / 3861\n",
      "41 / 3861\n",
      "42 / 3861\n",
      "43 / 3861\n",
      "44 / 3861\n",
      "45 / 3861\n",
      "46 / 3861\n",
      "47 / 3861\n",
      "48 / 3861\n",
      "49 / 3861\n",
      "50 / 3861\n",
      "51 / 3861\n",
      "52 / 3861\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-96cd6977485c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0msvc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rbf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \"\"\"\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \"\"\"\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseSVC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dense_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_dense_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobA_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobB_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvm_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m             cache_size=self.cache_size)\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sparse_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = split(scaled_v6, .25)\n",
    "\n",
    "Gs = np.arange(.1, 4, .1)\n",
    "Cs = np.arange(.1, 10, .1)\n",
    "\n",
    "steps = len(Gs) * len(Cs)\n",
    "scores = np.zeros((steps))\n",
    "index = 0\n",
    "top = (.1, .01, 0)\n",
    "\n",
    "for g in Gs:\n",
    "    for c in Cs:\n",
    "        print('%d / %d' % (index, steps))\n",
    "        svc = svm.SVC(kernel='rbf', C=c, gamma=g)\n",
    "        svc.fit(X_train, Y_train)\n",
    "        score = svc.score(X_test, Y_test)\n",
    "        scores[index] = score\n",
    "        if score > top[2]:\n",
    "            top = (c, g, score)\n",
    "        index += 1\n",
    "\n",
    "print('Top:', top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9625\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "sgd = linear_model.SGDClassifier(max_iter=200)\n",
    "sgd.fit(X_train, Y_train)\n",
    "score = sgd.score(X_test, Y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=30)\n",
    "knn.fit(X_train, Y_train)\n",
    "score = knn.score(X_test, Y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 26 (3)\n",
      "1 / 26 (4)\n",
      "2 / 26 (5)\n",
      "3 / 26 (6)\n",
      "4 / 26 (7)\n",
      "5 / 26 (8)\n",
      "6 / 26 (9)\n",
      "7 / 26 (10)\n",
      "8 / 26 (11)\n",
      "9 / 26 (12)\n",
      "10 / 26 (13)\n",
      "11 / 26 (14)\n",
      "12 / 26 (15)\n",
      "13 / 26 (16)\n",
      "14 / 26 (17)\n",
      "15 / 26 (18)\n",
      "16 / 26 (19)\n",
      "17 / 26 (20)\n",
      "18 / 26 (21)\n",
      "19 / 26 (22)\n",
      "20 / 26 (23)\n",
      "21 / 26 (24)\n",
      "22 / 26 (25)\n",
      "23 / 26 (26)\n",
      "24 / 26 (27)\n",
      "25 / 26 (28)\n",
      "26 / 26 (29)\n",
      "('Top:', (3, 0.97291666666666665))\n"
     ]
    }
   ],
   "source": [
    "Ns = range(3, 30)\n",
    "scores = np.zeros((len(Ns)))\n",
    "index = 0\n",
    "top = (3, 0)\n",
    "for n in Ns:\n",
    "    print('%d / %d (%d)' % (index, len(Ns)-1, n))\n",
    "    knn = KNeighborsClassifier(n_neighbors=n)\n",
    "    knn.fit(X_train, Y_train)\n",
    "    score = knn.score(X_test, Y_test)\n",
    "    scores[index] = score\n",
    "    if score > top[1]:\n",
    "        top = (n, score)\n",
    "    index += 1\n",
    "\n",
    "print('Top:', top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Automation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing v6 on AdaBoost ...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:   57.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'base_estimator': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=81, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), 'algorithm': 'SAMME'}\n",
      "MSE: 0.9609375\n",
      "\n",
      "Testing v6 on SVM/C ...\n",
      "Fitting 3 folds for each of 2970 candidates, totalling 8910 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   43.4s\n",
      "[Parallel(n_jobs=-1)]: Done 888 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1588 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2488 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3588 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4888 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done 6388 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 8088 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=-1)]: Done 8910 out of 8910 | elapsed: 12.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'kernel': 'rbf', 'C': 3.8000000000000003, 'gamma': 0.1}\n",
      "MSE: 0.983072916667\n",
      "\n",
      "Testing v6 on RandomForest ...\n",
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   23.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'n_estimators': 95}\n",
      "MSE: 0.969401041667\n",
      "\n",
      "Testing v6 on kNN ...\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 out of  27 | elapsed:    2.1s remaining:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'n_neighbors': 1}\n",
      "MSE: 0.97265625\n",
      "\n",
      "Testing v6 on SGD ...\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    9.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'max_iter': 500}\n",
      "MSE: 0.948567708333\n",
      "\n",
      "Testing v4 on AdaBoost ...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:   54.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'base_estimator': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=81, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), 'algorithm': 'SAMME'}\n",
      "MSE: 0.96484375\n",
      "\n",
      "Testing v4 on SVM/C ...\n",
      "Fitting 3 folds for each of 2970 candidates, totalling 8910 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=-1)]: Done 438 tasks      | elapsed:   45.9s\n",
      "[Parallel(n_jobs=-1)]: Done 938 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1638 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2538 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3638 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4938 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done 6438 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done 8138 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=-1)]: Done 8910 out of 8910 | elapsed: 15.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'kernel': 'rbf', 'C': 5.7000000000000002, 'gamma': 0.2}\n",
      "MSE: 0.979166666667\n",
      "\n",
      "Testing v4 on RandomForest ...\n",
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   25.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'n_estimators': 68}\n",
      "MSE: 0.965494791667\n",
      "\n",
      "Testing v4 on kNN ...\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 out of  27 | elapsed:    2.1s remaining:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'n_neighbors': 1}\n",
      "MSE: 0.968098958333\n",
      "\n",
      "Testing v4 on SGD ...\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    9.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'max_iter': 400}\n",
      "MSE: 0.94921875\n",
      "\n",
      "Testing Cleaned+MinMaxScaled on AdaBoost ...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:   31.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'base_estimator': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=81, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), 'algorithm': 'SAMME'}\n",
      "MSE: 0.951822916667\n",
      "\n",
      "Testing Cleaned+MinMaxScaled on SVM/C ...\n",
      "Fitting 3 folds for each of 2970 candidates, totalling 8910 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=-1)]: Done 888 tasks      | elapsed:   56.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1588 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2488 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3588 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4888 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 6388 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 8106 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 8910 out of 8910 | elapsed:  6.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'kernel': 'rbf', 'C': 4.0999999999999996, 'gamma': 0.5}\n",
      "MSE: 0.97265625\n",
      "\n",
      "Testing Cleaned+MinMaxScaled on RandomForest ...\n",
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   22.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'n_estimators': 95}\n",
      "MSE: 0.951171875\n",
      "\n",
      "Testing Cleaned+MinMaxScaled on kNN ...\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "Params: {'n_neighbors': 1}\n",
      "MSE: 0.956380208333\n",
      "\n",
      "Testing Cleaned+MinMaxScaled on SGD ...\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    5.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'max_iter': 300}\n",
      "MSE: 0.953125\n",
      "\n",
      "Testing Cleaned+Extended+MinMaxScaled on AdaBoost ...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'base_estimator': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=81, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), 'algorithm': 'SAMME'}\n",
      "MSE: 0.96484375\n",
      "\n",
      "Testing Cleaned+Extended+MinMaxScaled on SVM/C ...\n",
      "Fitting 3 folds for each of 2970 candidates, totalling 8910 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   46.9s\n",
      "[Parallel(n_jobs=-1)]: Done 888 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1588 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2488 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3588 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4888 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 6388 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 8088 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=-1)]: Done 8910 out of 8910 | elapsed: 14.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'kernel': 'rbf', 'C': 2.9000000000000004, 'gamma': 0.1}\n",
      "MSE: 0.981770833333\n",
      "\n",
      "Testing Cleaned+Extended+MinMaxScaled on RandomForest ...\n",
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   22.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'n_estimators': 82}\n",
      "MSE: 0.967447916667\n",
      "\n",
      "Testing Cleaned+Extended+MinMaxScaled on kNN ...\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "Params: {'n_neighbors': 3}\n",
      "MSE: 0.970052083333\n",
      "\n",
      "Testing Cleaned+Extended+MinMaxScaled on SGD ...\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   11.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'max_iter': 300}\n",
      "MSE: 0.948567708333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "\n",
    "datasets = [\n",
    "    ('v6', scaled_v6),\n",
    "    ('v4', scaled_v4),\n",
    "    ('Cleaned+MinMaxScaled', minmaxscaled),\n",
    "    ('Cleaned+Extended+MinMaxScaled', minmaxscaled_ext)\n",
    "]\n",
    "\n",
    "options = {\n",
    "    'AdaBoost': {\n",
    "        'base_estimator': [\n",
    "            svm.SVC(kernel='rbf', C=3.0, gamma=0.2),\n",
    "            RandomForestClassifier(n_estimators=81)\n",
    "        ],\n",
    "        'algorithm': ['SAMME']\n",
    "    },\n",
    "    'SVM/C': {\n",
    "        'kernel': ('linear', 'rbf'),\n",
    "        'C': np.arange(.1, 10.0, .1),\n",
    "        'gamma': [.001, .005, .01, .03, .05, .08, .1, .2, .25, .3, .5, 1, 3, 5, 8]\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'n_estimators': range(60, 100)\n",
    "    },\n",
    "    'kNN': {\n",
    "        'n_neighbors': range(1, 10)\n",
    "    },\n",
    "    'SGD': {\n",
    "        'max_iter': [300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "    }\n",
    "}\n",
    "\n",
    "classifiers = [\n",
    "    ('AdaBoost', AdaBoostClassifier),\n",
    "    ('SVM/C', svm.SVC),\n",
    "    ('RandomForest', RandomForestClassifier),\n",
    "    ('kNN', KNeighborsClassifier),\n",
    "    ('SGD', linear_model.SGDClassifier)\n",
    "]\n",
    "\n",
    "def search(classifiers, options, datasets, test_size, random_state):\n",
    "    results = {\n",
    "        'rank': [],\n",
    "        'classifier': [],\n",
    "        'options': [],\n",
    "        'dataset': [],\n",
    "        'score': []\n",
    "    }\n",
    "\n",
    "    for dataset in datasets:\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(dataset[1].iloc[:,:-1], dataset[1].iloc[:,-1],\\\n",
    "                                                            test_size=test_size, random_state=random_state)\n",
    "        \n",
    "        for classifier in classifiers:\n",
    "            name = classifier[0]\n",
    "            print 'Testing', dataset[0], 'on', name, '...'\n",
    "\n",
    "            model = GridSearchCV(classifier[1](), options[name], verbose=1, n_jobs=-1, cv=3)\n",
    "            model.fit(X_train, Y_train)\n",
    "            \n",
    "            print 'Params:', model.best_params_\n",
    "            print 'MSE:', model.best_score_\n",
    "            print\n",
    "            \n",
    "            results['rank'].append(0)\n",
    "            results['classifier'].append(name)\n",
    "            results['options'].append(str(model.best_params_))\n",
    "            results['dataset'].append(dataset[0])\n",
    "            results['score'].append(model.best_score_)\n",
    "            \n",
    "    return results\n",
    "\n",
    "results = search(classifiers, options, datasets, .20, 123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results).sort_values(['score'], ascending=[False])\n",
    "results_df['rank'] = pd.Series(range(1, len(results_df) + 1), index=results_df.index)\n",
    "# results_df[['rank', 'classifier', 'options', 'dataset', 'score']].to_csv('../classifiers/results_20181107221100_20_123456.csv', sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy', 0.98177083333333337)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "best = svm.SVC(kernel='rbf', C=3.8, gamma=0.1)\n",
    "X_train, X_test, Y_train, Y_test = split(scaled_v6, .20)\n",
    "Y_pred = best.fit(X_train, Y_train).predict(X_test)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes):\n",
    "#     print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "\n",
    "print('Accuracy', best.score(X_test, Y_test))\n",
    "plot_confusion_matrix(cnf_matrix, classes=range(0,10))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
