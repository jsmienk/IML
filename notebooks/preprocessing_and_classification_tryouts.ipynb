{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing & Classification Try-Outs\n",
    "\n",
    "## Datasets\n",
    "\n",
    "- ~~Full~~\n",
    "- ~~Cleaned~~\n",
    "- ~~Cleaned+MinMaxScaled~~\n",
    "- ~~Cleaned+RobustScaled~~\n",
    "- ~~Cleaned+QuantileTransformed~~\n",
    "- Cleaned+Extended+MinMaxScaled\n",
    "- Cleaned+CleanExtended+MinMaxScaled\n",
    "- v4 (?)\n",
    "- v5 (mixed with MNIST digits)\n",
    "- v6 (Automatic Feature Selection)\n",
    "\n",
    "## Classifiers\n",
    "\n",
    "- ~~RandomForest~~\n",
    "- SVM/C\n",
    "- kNN\n",
    "- ~~SGD~~\n",
    "\n",
    "## Winner\n",
    "\n",
    "SVM/C `kernel='rbf', C=3.8, gamma=0.1` with v6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS AND NOTEBOOK SETUP\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# | Rank | Classifier | Options | Dataset | Score\n",
    "--- | --- | --- | --- | ---| ---\n",
    "1 |1 |SVM/C | `kernel='rbf', C=1.5, gamma=0.2` | Cleaned+Extended+MinMaxScaled | `0.98541666666666672`\n",
    "2 |1 |SVM/C | `kernel='rbf', C=8.7, gamma=0.04` | Cleaned+Extended+MinMaxScaled | `0.98333333333333328`\n",
    "3 |1 |kNN | `n_neigbors=3` | Cleaned+Extended+MinMaxScaled | `0.98333333333333328`\n",
    "4 |1 |SVM/C | `kernel='rbf', C=3.0, gamma=0.2` | Cleaned+CleanExtended+MinMaxScaled | `0.97916666666666663`\n",
    "\n",
    "Default options:\n",
    "\n",
    "- Scikit Learn train/test split ratio: `.25`.\n",
    "- Normalizing all columns but `num_holes`.\n",
    "\n",
    "## outdated\n",
    "\n",
    "\\# | Rank | Classifier | Options | Dataset | Score\n",
    "--- | --- | --- | --- | ---| ---\n",
    "1 |1 |SVM/C | `kernel='rbf', C=6.6, gamma=0.35` | Cleaned+MinMaxScaled | `0.978873239436`\n",
    "1 |1 |SVM/C | `kernel='rbf', C=3.9, gamma=0.59` | Cleaned+MinMaxScaled | `0.978873239436`\n",
    "1 |1 |SVM/C | `C=2.0` | Cleaned+MinMaxScaled | `0.973958333333`\n",
    "2 |1 |SVM/C | `C=4.9` | Cleaned+RobustScaled | `0.973958333333`\n",
    "3 |3 |SVM/C | `kernel='rbf', C=3.9` | Cleaned+MinMaxScaled | `0.967391304347`\n",
    "4 |3 |SVM/C | `kernel='sigmoid', C=9.6` | Cleaned+MinMaxScaled | `0.967391304347`\n",
    "5 |5 |RandomForest | `n_estimators=70` | Cleaned | `0.953125000000`\n",
    "6 |5 |RandomForest | `n_estimators=70` | Cleaned+MinMaxScaled | `0.953125000000`\n",
    "7 |5 |SVM/C | `C=2.6` | Cleaned+QuantileTransformed | `0.953125000000`\n",
    "8 |8 |SVM/C | `C=4.3` | Cleaned | `0.947916666667`\n",
    "9 |8 |RandomForest | `n_estimators=16` | Cleaned+RobustScaled | `0.947916666667`\n",
    "10|8 |RandomForest | `n_estimators=32` | Cleaned+QuantileTransformed | `0.947916666667`\n",
    "11|11|RandomForest | `n_estimators=90` | Full | `0.942708333333`\n",
    "12|12|SVM/C | `default` | Full | `0.932291666667`\n",
    "\n",
    "Default options:\n",
    "\n",
    "- RandomForest with `n_estimators=50`, `oob_score=True` and `random_state=123456`.\n",
    "- SVM/C with `kernel=linear`, `C=1.0`.\n",
    "\n",
    "Normalizing all columns but `num_holes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING OUR DATASET\n",
    "data_full = pd.read_csv('../dataset-numpy/dataset.csv')\n",
    "data_clean_manual = pd.read_csv('../dataset-numpy/dataset-clean-manual.csv')\n",
    "data_ext_clean_manual = pd.read_csv('../dataset-numpy/dataset-extended-clean-manual.csv')\n",
    "data_v4 = pd.read_csv('../dataset-numpy/dataset-v4.csv')\n",
    "data_v6 = pd.read_csv('../dataset-numpy/dataset-v6.csv')\n",
    "data_v7 = pd.read_csv('../dataset-numpy/dataset-clean-v7.csv')\n",
    "data_v8 = pd.read_csv('../dataset-numpy/dataset-v8.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "less_columns = data_clean_manual.columns.values\n",
    "columns_v4 = data_v4.columns.values\n",
    "columns_v6 = data_v6.columns.values\n",
    "columns_v7 = data_v7.columns.values\n",
    "columns_v8 = data_v8.columns.values\n",
    "columns_to_not_normalize = ['num_holes', 'label']\n",
    "\n",
    "columns_v4_to_normalize = [c for c in columns_v4 if not c in columns_to_not_normalize]\n",
    "columns_v6_to_normalize = [c for c in columns_v6 if not c in columns_to_not_normalize]\n",
    "columns_v7_to_normalize = [c for c in columns_v7 if not c in columns_to_not_normalize]\n",
    "columns_v8_to_normalize = [c for c in columns_v8 if not c in columns_to_not_normalize]\n",
    "less_columns_to_normalize = [c for c in less_columns if not c in columns_to_not_normalize]\n",
    "        \n",
    "def scale(data, scaler, columns):\n",
    "    return pd.DataFrame(scaler.fit_transform(data[columns]), columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 24) (1920, 72) (1920, 60) (1920, 56) (1920, 58) (1920, 79)\n",
      "Index([u'area', u'contours', u'radius', u'hull_radius', u'centroid_x',\n",
      "       u'centroid_y', u'angle', u'weight_0_2', u'weight_0_3', u'weight_0_4',\n",
      "       u'weight_0_5', u'weight_0_6', u'weight_1_1', u'weight_1_2',\n",
      "       u'weight_1_3', u'weight_1_4', u'weight_1_5', u'weight_1_6',\n",
      "       u'weight_2_1', u'weight_2_2', u'weight_2_3', u'weight_2_4',\n",
      "       u'weight_2_5', u'weight_2_6', u'weight_3_1', u'weight_3_2',\n",
      "       u'weight_3_3', u'weight_3_4', u'weight_3_5', u'weight_3_6',\n",
      "       u'weight_4_1', u'weight_4_2', u'weight_4_3', u'weight_4_4',\n",
      "       u'weight_4_5', u'weight_4_6', u'weight_5_1', u'weight_5_2',\n",
      "       u'weight_5_3', u'weight_5_4', u'weight_5_5', u'weight_5_6',\n",
      "       u'weight_6_1', u'weight_6_2', u'weight_6_3', u'weight_6_4',\n",
      "       u'weight_6_5', u'weight_6_6', u'weight_7_2', u'weight_7_3',\n",
      "       u'weight_7_4', u'weight_7_5', u'weight_7_6', u'weight_7_7',\n",
      "       u'num_holes', u'label'],\n",
      "      dtype='object')\n",
      "Index([u'area', u'width', u'contours', u'radius', u'centroid_x', u'centroid_y',\n",
      "       u'corners', u'circles', u'angle', u'weight_0_2', u'weight_0_3',\n",
      "       u'weight_0_4', u'weight_0_5', u'weight_0_6', u'weight_1_1',\n",
      "       u'weight_1_2', u'weight_1_3', u'weight_1_4', u'weight_1_5',\n",
      "       u'weight_1_6', u'weight_2_1', u'weight_2_2', u'weight_2_3',\n",
      "       u'weight_2_4', u'weight_2_5', u'weight_2_6', u'weight_3_1',\n",
      "       u'weight_3_2', u'weight_3_3', u'weight_3_4', u'weight_3_5',\n",
      "       u'weight_3_6', u'weight_4_1', u'weight_4_2', u'weight_4_3',\n",
      "       u'weight_4_4', u'weight_4_5', u'weight_4_6', u'weight_5_1',\n",
      "       u'weight_5_2', u'weight_5_3', u'weight_5_4', u'weight_5_5',\n",
      "       u'weight_5_6', u'weight_6_1', u'weight_6_2', u'weight_6_3',\n",
      "       u'weight_6_4', u'weight_6_5', u'weight_6_6', u'weight_7_2',\n",
      "       u'weight_7_3', u'weight_7_4', u'weight_7_5', u'weight_7_6',\n",
      "       u'weight_7_7', u'num_holes', u'label'],\n",
      "      dtype='object')\n",
      "Index([u'area', u'width', u'contours', u'radius', u'circle_dist', u'rect_dist',\n",
      "       u'hull_radius', u'aspect_ratio', u'centroid_x', u'centroid_y',\n",
      "       u'corners', u'circles', u'angle', u'weight_0_0', u'weight_0_1',\n",
      "       u'weight_0_2', u'weight_0_3', u'weight_0_4', u'weight_0_5',\n",
      "       u'weight_0_6', u'weight_0_7', u'weight_1_0', u'weight_1_1',\n",
      "       u'weight_1_2', u'weight_1_3', u'weight_1_4', u'weight_1_5',\n",
      "       u'weight_1_6', u'weight_1_7', u'weight_2_0', u'weight_2_1',\n",
      "       u'weight_2_2', u'weight_2_3', u'weight_2_4', u'weight_2_5',\n",
      "       u'weight_2_6', u'weight_2_7', u'weight_3_0', u'weight_3_1',\n",
      "       u'weight_3_2', u'weight_3_3', u'weight_3_4', u'weight_3_5',\n",
      "       u'weight_3_6', u'weight_3_7', u'weight_4_0', u'weight_4_1',\n",
      "       u'weight_4_2', u'weight_4_3', u'weight_4_4', u'weight_4_5',\n",
      "       u'weight_4_6', u'weight_4_7', u'weight_5_0', u'weight_5_1',\n",
      "       u'weight_5_2', u'weight_5_3', u'weight_5_4', u'weight_5_5',\n",
      "       u'weight_5_6', u'weight_5_7', u'weight_6_0', u'weight_6_1',\n",
      "       u'weight_6_2', u'weight_6_3', u'weight_6_4', u'weight_6_5',\n",
      "       u'weight_6_6', u'weight_6_7', u'weight_7_0', u'weight_7_1',\n",
      "       u'weight_7_2', u'weight_7_3', u'weight_7_4', u'weight_7_5',\n",
      "       u'weight_7_6', u'weight_7_7', u'num_holes', u'label'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "minmaxscaled = data_clean_manual.copy()\n",
    "minmaxscaled[less_columns_to_normalize] = scale(data_clean_manual, MinMaxScaler(), less_columns_to_normalize)\n",
    "\n",
    "minmaxscaled_ext = data_ext_clean_manual.copy()\n",
    "minmaxscaled_ext[columns_v4_to_normalize] = scale(data_ext_clean_manual, MinMaxScaler(), columns_v4_to_normalize)\n",
    "\n",
    "scaled_v4 = data_v4.copy()\n",
    "scaled_v4[columns_v4_to_normalize] = scale(data_v4, MinMaxScaler(), columns_v4_to_normalize)\n",
    "\n",
    "scaled_v6 = data_v6.copy()\n",
    "scaled_v6[columns_v6_to_normalize] = scale(data_v6, MinMaxScaler(), columns_v6_to_normalize)\n",
    "\n",
    "scaled_v7 = data_v7.copy()\n",
    "scaled_v7[columns_v7_to_normalize] = scale(data_v7, MinMaxScaler(), columns_v7_to_normalize)\n",
    "\n",
    "scaled_v8 = data_v8.copy()\n",
    "scaled_v8[columns_v8_to_normalize] = scale(data_v8, MinMaxScaler(), columns_v8_to_normalize)\n",
    "\n",
    "# del scaled_v7['area']\n",
    "# del scaled_v7['contours']\n",
    "# del scaled_v7['radius']\n",
    "# del scaled_v7['hull_radius']\n",
    "# del scaled_v7['angle']\n",
    "# del scaled_v7['corners']\n",
    "# del scaled_v7['circles']\n",
    "# del scaled_v7['centroid_x']\n",
    "# del scaled_v7['centroid_y']\n",
    "# del scaled_v7['num_holes']\n",
    "\n",
    "print minmaxscaled.shape, minmaxscaled_ext.shape, scaled_v4.shape, scaled_v6.shape, scaled_v7.shape, scaled_v8.shape\n",
    "print scaled_v6.columns\n",
    "print scaled_v7.columns\n",
    "print scaled_v8.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ~~RobustScaler~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "robustscaled = data_clean_manual.copy()\n",
    "robustscaled[columns] = scale(data_clean_manual, RobustScaler(), columns)\n",
    "robustscaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ~~QuantileTransformer~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "quantiletransformed = data_clean_manual.copy()\n",
    "quantiletransformed[columns] = scale(data_clean_manual, QuantileTransformer(), columns)\n",
    "quantiletransformed.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split(data, ratio, random_state=None):\n",
    "    return train_test_split(data.iloc[:,:-1], data.iloc[:,-1], test_size=ratio, random_state=random_state)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = split(scaled_v7, .25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('N_E:', 2, 'Score:', 0.82499999999999996)\n",
      "('N_E:', 3, 'Score:', 0.90208333333333335)\n",
      "('N_E:', 4, 'Score:', 0.90625)\n",
      "('N_E:', 5, 'Score:', 0.93125000000000002)\n",
      "('N_E:', 6, 'Score:', 0.94166666666666665)\n",
      "('N_E:', 7, 'Score:', 0.94999999999999996)\n",
      "('N_E:', 10, 'Score:', 0.9604166666666667)\n",
      "('N_E:', 11, 'Score:', 0.96250000000000002)\n",
      "('N_E:', 15, 'Score:', 0.96458333333333335)\n",
      "('N_E:', 16, 'Score:', 0.96666666666666667)\n",
      "('N_E:', 27, 'Score:', 0.96875)\n",
      "('Top:', (27, 0.96875))\n"
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "top_rf = (2, 0.0)\n",
    "for n_e in range(2, 101):\n",
    "    rf = RandomForestClassifier(n_estimators=n_e, oob_score=True, random_state=123456)\n",
    "    rf.fit(X_train, Y_train)\n",
    "    score = rf.score(X_test, Y_test)\n",
    "    if score > top_rf[1]:\n",
    "        top_rf = (n_e, score)\n",
    "        print('N_E:', n_e, 'Score:', score)\n",
    "print('Top:', top_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Support Vector Machine\n",
    "\n",
    "100 x random train test split:\n",
    "\n",
    "\\# | Dataset | Options | Min | Max | Mean | Variance\n",
    "---| --- | --- | --- | --- | --- | ---\n",
    "1 | v8 | `kernel=rbf, C=3.65, gamme=0.1` | `1.0` | `1.0` | `1.0` | `1.0`\n",
    "1 | v6 | `kernel='rbf', C=3.8, gamma=0.1` | `0.9531250000` | `1.0000000000` | `0.9841666666` | `0.031041666`\n",
    "1 | Cleaned+Extended+MinMaxScaled | `kernel='rbf', C=1.5, gamma=0.2` | `0.9708333333` | `0.9937500000` | `0.9837291666` | `0.022916667`\n",
    "2 | ~~Cleaned+CleanExtended+MinMaxScaled~~ | `kernel='rbf', C=3.0, gamma=0.2` | `0.9687500000` | `0.9958333333` | `0.9814791666` | `0.027083333`\n",
    "3 | Cleaned+Extended+MinMaxScaled | `kernel='linear', C=1.1` | `0.9604166666` | `0.9916666666` | `0.9743750000`\n",
    "4 | Cleaned+MinMaxScaled | `kernel='rbf', C=6.6, gamma=0.35` | `0.9500000000` | `0.9833333333` | `0.9712708333`\n",
    "5 | ~~Cleaned+CleanExtended+MinMaxScaled~~ | `kernel='linear', C=0.4` | `0.9437500000` | `0.9875000000` | `0.9702708333`\n",
    "6 | Cleaned+MinMaxScaled | `kernel='linear', C=1.5` | `0.9395833333` | `0.9812500000` | `0.9626250000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Score: 0.96875\n",
      "Max Score: 0.997395833333\n",
      "Mean Score: 0.984973958333\n",
      "\n",
      "Min Score: 0.963541666667\n",
      "Max Score: 0.994791666667\n",
      "Mean Score: 0.983723958333\n",
      "\n",
      "Min Score: 0.96875\n",
      "Max Score: 0.997395833333\n",
      "Mean Score: 0.983854166667\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn import svm\n",
    "\n",
    "ITERS = 100\n",
    "scores = np.zeros((ITERS))\n",
    "\n",
    "for i in range(ITERS):\n",
    "    X_train, X_test, Y_train, Y_test = split(scaled_v8, .20)\n",
    "    svc = svm.SVC(kernel='rbf', C=3.65, gamma=0.1)\n",
    "    svc.fit(X_train, Y_train)\n",
    "    scores[i] = svc.score(X_test, Y_test)\n",
    "\n",
    "print 'Min Score:', scores.min()\n",
    "print 'Max Score:', scores.max()\n",
    "print 'Mean Score:', scores.mean()\n",
    "\n",
    "print\n",
    "\n",
    "for i in range(ITERS):\n",
    "    X_train, X_test, Y_train, Y_test = split(scaled_v7, .20)\n",
    "    svc = svm.SVC(kernel='rbf', C=3.8, gamma=0.1)\n",
    "    svc.fit(X_train, Y_train)\n",
    "    scores[i] = svc.score(X_test, Y_test)\n",
    "\n",
    "print 'Min Score:', scores.min()\n",
    "print 'Max Score:', scores.max()\n",
    "print 'Mean Score:', scores.mean()\n",
    "\n",
    "print\n",
    "\n",
    "for i in range(ITERS):\n",
    "    X_train, X_test, Y_train, Y_test = split(scaled_v6, .20)\n",
    "    svc = svm.SVC(kernel='rbf', C=3.8, gamma=0.1)\n",
    "    svc.fit(X_train, Y_train)\n",
    "    scores[i] = svc.score(X_test, Y_test)\n",
    "\n",
    "print 'Min Score:', scores.min()\n",
    "print 'Max Score:', scores.max()\n",
    "print 'Mean Score:', scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ~~Compared Datasets with Same Options~~\n",
    "\n",
    "### Outdated\n",
    "\n",
    "300 Iterations of 25% splits.\n",
    "\n",
    "Options: `kernel='rbf', C=2.8, gamma=0.1`\n",
    "\n",
    "Options: `kernel='rbf', C=3.0, gamma=0.2`\n",
    "\n",
    "\\# | Dataset | Min Score | Mean Score | Max Score\n",
    "---| --- | --- | --- | ---\n",
    "1| v4 | `0.96458333` | `0.98163194`| `0.99583333`\n",
    "2| Cleaned+MinMaxScaled+Extended | `0.96041666` | `0.98059722` | `0.99583333`\n",
    "3| Cleaned+MinMaxScaled | `0.94791666` | `0.96754861` | `0.98541666`\n",
    "\n",
    "Options: `kernel='rbf', C=1.5, gamma=0.2`\n",
    "\n",
    "\\# | Dataset | Min Score | Mean Score | Max Score\n",
    "---| --- | --- | --- | ---\n",
    "1| v4 | `0.96666666` | `0.98113888`| `0.99583333`\n",
    "2| Cleaned+MinMaxScaled+Extended | `0.96041666` | `0.97952083` | `0.99375000`\n",
    "3| Cleaned+MinMaxScaled | `0.93750000` | `0.95971527` | `0.98125000`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating on unseen data using KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1728, 55) (192, 55) (1728,) (192,)\n"
     ]
    }
   ],
   "source": [
    "DATASET = scaled_v6\n",
    "X, X_validation, Y, Y_validation = split(DATASET, .1, random_state=444)\n",
    "\n",
    "print X.shape, X_validation.shape, Y.shape, Y_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.983796296296\n",
      "Score: 0.978009259259\n",
      "\n",
      "Score:  0.942708333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=2)\n",
    "svc = svm.SVC(kernel='rbf', C=3.65, gamma=0.1)\n",
    "\n",
    "for train, test in kf.split(X):\n",
    "    X_train, X_test, Y_train, Y_test = X.iloc[train], X.iloc[test], Y.iloc[train], Y.iloc[test]\n",
    "    # Testing on train/test data\n",
    "    svc.fit(X_train, Y_train)\n",
    "    print 'Score:', svc.score(X_test, Y_test)\n",
    "\n",
    "print\n",
    "# Validating on unseen validation data\n",
    "print 'Score: ', svc.score(X_validation, Y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the optimal C and Gamma for RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 900\n",
      "[ 1.5   0.1   0.98]\n",
      "1 / 900\n",
      "2 / 900\n",
      "[ 1.6   0.1   0.99]\n",
      "3 / 900\n",
      "4 / 900\n",
      "5 / 900\n",
      "6 / 900\n",
      "7 / 900\n",
      "8 / 900\n",
      "9 / 900\n",
      "10 / 900\n",
      "11 / 900\n",
      "12 / 900\n",
      "13 / 900\n",
      "14 / 900\n",
      "15 / 900\n",
      "16 / 900\n",
      "17 / 900\n",
      "18 / 900\n",
      "19 / 900\n",
      "20 / 900\n",
      "21 / 900\n",
      "22 / 900\n",
      "23 / 900\n",
      "24 / 900\n",
      "25 / 900\n",
      "26 / 900\n",
      "27 / 900\n",
      "28 / 900\n",
      "29 / 900\n",
      "30 / 900\n",
      "31 / 900\n",
      "32 / 900\n",
      "33 / 900\n",
      "34 / 900\n",
      "35 / 900\n",
      "36 / 900\n",
      "37 / 900\n",
      "38 / 900\n",
      "39 / 900\n",
      "40 / 900\n",
      "41 / 900\n",
      "42 / 900\n",
      "43 / 900\n",
      "[ 3.65  0.1   0.99]\n",
      "44 / 900\n",
      "45 / 900\n",
      "46 / 900\n",
      "47 / 900\n",
      "48 / 900\n",
      "49 / 900\n",
      "50 / 900\n",
      "51 / 900\n",
      "52 / 900\n",
      "53 / 900\n",
      "54 / 900\n",
      "55 / 900\n",
      "56 / 900\n",
      "57 / 900\n",
      "58 / 900\n",
      "59 / 900\n",
      "60 / 900\n",
      "61 / 900\n",
      "62 / 900\n",
      "63 / 900\n",
      "64 / 900\n",
      "65 / 900\n",
      "66 / 900\n",
      "67 / 900\n",
      "68 / 900\n",
      "69 / 900\n",
      "70 / 900\n",
      "71 / 900\n",
      "72 / 900\n",
      "73 / 900\n",
      "74 / 900\n",
      "75 / 900\n",
      "76 / 900\n",
      "77 / 900\n",
      "78 / 900\n",
      "79 / 900\n",
      "80 / 900\n",
      "81 / 900\n",
      "82 / 900\n",
      "83 / 900\n",
      "84 / 900\n",
      "85 / 900\n",
      "86 / 900\n",
      "87 / 900\n",
      "88 / 900\n",
      "89 / 900\n",
      "90 / 900\n",
      "91 / 900\n",
      "92 / 900\n",
      "93 / 900\n",
      "94 / 900\n",
      "95 / 900\n",
      "96 / 900\n",
      "97 / 900\n",
      "98 / 900\n",
      "99 / 900\n",
      "100 / 900\n",
      "101 / 900\n",
      "102 / 900\n",
      "103 / 900\n",
      "104 / 900\n",
      "105 / 900\n",
      "106 / 900\n",
      "107 / 900\n",
      "108 / 900\n",
      "109 / 900\n",
      "110 / 900\n",
      "111 / 900\n",
      "112 / 900\n",
      "113 / 900\n",
      "114 / 900\n",
      "115 / 900\n",
      "116 / 900\n",
      "117 / 900\n",
      "118 / 900\n",
      "119 / 900\n",
      "120 / 900\n",
      "121 / 900\n",
      "122 / 900\n",
      "123 / 900\n",
      "124 / 900\n",
      "125 / 900\n",
      "126 / 900\n",
      "127 / 900\n",
      "128 / 900\n",
      "129 / 900\n",
      "130 / 900\n",
      "131 / 900\n",
      "132 / 900\n",
      "133 / 900\n",
      "134 / 900\n",
      "135 / 900\n",
      "136 / 900\n",
      "137 / 900\n",
      "138 / 900\n",
      "139 / 900\n",
      "140 / 900\n",
      "141 / 900\n",
      "142 / 900\n",
      "143 / 900\n",
      "144 / 900\n",
      "145 / 900\n",
      "146 / 900\n",
      "147 / 900\n",
      "148 / 900\n",
      "149 / 900\n",
      "150 / 900\n",
      "151 / 900\n",
      "152 / 900\n",
      "153 / 900\n",
      "154 / 900\n",
      "155 / 900\n",
      "156 / 900\n",
      "157 / 900\n",
      "158 / 900\n",
      "159 / 900\n",
      "160 / 900\n",
      "161 / 900\n",
      "162 / 900\n",
      "163 / 900\n",
      "164 / 900\n",
      "165 / 900\n",
      "166 / 900\n",
      "167 / 900\n",
      "168 / 900\n",
      "169 / 900\n",
      "170 / 900\n",
      "171 / 900\n",
      "172 / 900\n",
      "173 / 900\n",
      "174 / 900\n",
      "175 / 900\n",
      "176 / 900\n",
      "177 / 900\n",
      "178 / 900\n",
      "179 / 900\n",
      "180 / 900\n",
      "181 / 900\n",
      "182 / 900\n",
      "183 / 900\n",
      "184 / 900\n",
      "185 / 900\n",
      "186 / 900\n",
      "187 / 900\n",
      "188 / 900\n",
      "189 / 900\n",
      "190 / 900\n",
      "191 / 900\n",
      "192 / 900\n",
      "193 / 900\n",
      "194 / 900\n",
      "195 / 900\n",
      "196 / 900\n",
      "197 / 900\n",
      "198 / 900\n",
      "199 / 900\n",
      "200 / 900\n",
      "201 / 900\n",
      "202 / 900\n",
      "203 / 900\n",
      "204 / 900\n",
      "205 / 900\n",
      "206 / 900\n",
      "207 / 900\n",
      "208 / 900\n",
      "209 / 900\n",
      "210 / 900\n",
      "211 / 900\n",
      "212 / 900\n",
      "213 / 900\n",
      "214 / 900\n",
      "215 / 900\n",
      "216 / 900\n",
      "217 / 900\n",
      "218 / 900\n",
      "219 / 900\n",
      "220 / 900\n",
      "221 / 900\n",
      "222 / 900\n",
      "223 / 900\n",
      "224 / 900\n",
      "225 / 900\n",
      "226 / 900\n",
      "227 / 900\n",
      "228 / 900\n",
      "229 / 900\n",
      "230 / 900\n",
      "231 / 900\n",
      "232 / 900\n",
      "233 / 900\n",
      "234 / 900\n",
      "235 / 900\n",
      "236 / 900\n",
      "237 / 900\n",
      "238 / 900\n",
      "239 / 900\n",
      "240 / 900\n",
      "241 / 900\n",
      "242 / 900\n",
      "243 / 900\n",
      "244 / 900\n",
      "245 / 900\n",
      "246 / 900\n",
      "247 / 900\n",
      "248 / 900\n",
      "249 / 900\n",
      "250 / 900\n",
      "251 / 900\n",
      "252 / 900\n",
      "253 / 900\n",
      "254 / 900\n",
      "255 / 900\n",
      "256 / 900\n",
      "257 / 900\n",
      "258 / 900\n",
      "259 / 900\n",
      "260 / 900\n",
      "261 / 900\n",
      "262 / 900\n",
      "263 / 900\n",
      "264 / 900\n",
      "265 / 900\n",
      "266 / 900\n",
      "267 / 900\n",
      "268 / 900\n",
      "269 / 900\n",
      "270 / 900\n",
      "271 / 900\n",
      "272 / 900\n",
      "273 / 900\n",
      "274 / 900\n",
      "275 / 900\n",
      "276 / 900\n",
      "277 / 900\n",
      "278 / 900\n",
      "279 / 900\n",
      "280 / 900\n",
      "281 / 900\n",
      "282 / 900\n",
      "283 / 900\n",
      "284 / 900\n",
      "285 / 900\n",
      "286 / 900\n",
      "287 / 900\n",
      "288 / 900\n",
      "289 / 900\n",
      "290 / 900\n",
      "291 / 900\n",
      "292 / 900\n",
      "293 / 900\n",
      "294 / 900\n",
      "295 / 900\n",
      "296 / 900\n",
      "297 / 900\n",
      "298 / 900\n",
      "299 / 900\n",
      "300 / 900\n",
      "301 / 900\n",
      "302 / 900\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-b37318dd7bb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%d / %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0msvc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rbf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = split(scaled_v8, .20)\n",
    "\n",
    "Gs = np.arange(.1, 1, .05)\n",
    "Cs = np.arange(1.5, 4, .05)\n",
    "\n",
    "steps = len(Gs) * len(Cs)\n",
    "scores = np.array([np.zeros((3)) for s in range(steps)])\n",
    "index = 0\n",
    "top = [.1, .1, 0]\n",
    "\n",
    "for g in Gs:\n",
    "    for c in Cs:\n",
    "        print('%d / %d' % (index, steps))\n",
    "        svc = svm.SVC(kernel='rbf', C=c, gamma=g)\n",
    "        svc.fit(X_train, Y_train)\n",
    "        score = svc.score(X_test, Y_test)\n",
    "        scores[index] = np.array([c, g, score])\n",
    "        if score > top[2]:\n",
    "            top = scores[index]\n",
    "            print top\n",
    "        index += 1\n",
    "\n",
    "print 'Top:', top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fea86ff8690>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "npscores = np.array(scores[:300])\n",
    "plt.scatter(range(len(npscores)), npscores[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "sgd = linear_model.SGDClassifier(max_iter=200)\n",
    "sgd.fit(X_train, Y_train)\n",
    "score = sgd.score(X_test, Y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=30)\n",
    "knn.fit(X_train, Y_train)\n",
    "score = knn.score(X_test, Y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Ns = range(3, 30)\n",
    "scores = np.zeros((len(Ns)))\n",
    "index = 0\n",
    "top = (3, 0)\n",
    "for n in Ns:\n",
    "    print('%d / %d (%d)' % (index, len(Ns)-1, n))\n",
    "    knn = KNeighborsClassifier(n_neighbors=n)\n",
    "    knn.fit(X_train, Y_train)\n",
    "    score = knn.score(X_test, Y_test)\n",
    "    scores[index] = score\n",
    "    if score > top[1]:\n",
    "        top = (n, score)\n",
    "    index += 1\n",
    "\n",
    "print('Top:', top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Automation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing v8 on AdaBoost ...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'base_estimator': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=81, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), 'algorithm': 'SAMME'}\n",
      "MSE: 0.969401041667\n",
      "\n",
      "Testing v8 on SVM/C ...\n",
      "Fitting 3 folds for each of 156 candidates, totalling 468 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   31.2s\n",
      "[Parallel(n_jobs=-1)]: Done 468 out of 468 | elapsed:   37.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'kernel': 'rbf', 'C': 1.0000000000000004, 'gamma': 0.1}\n",
      "MSE: 0.979817708333\n",
      "\n",
      "Testing v8 on RandomForest ...\n",
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   23.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'n_estimators': 88}\n",
      "MSE: 0.974609375\n",
      "\n",
      "Testing v8 on kNN ...\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 out of  27 | elapsed:    3.0s remaining:    0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'n_neighbors': 4}\n",
      "MSE: 0.973958333333\n",
      "\n",
      "Testing v8 on SGD ...\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   13.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'max_iter': 400}\n",
      "MSE: 0.95703125\n",
      "\n",
      "Testing v7 on AdaBoost ...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:   57.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'base_estimator': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=81, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), 'algorithm': 'SAMME'}\n",
      "MSE: 0.967447916667\n",
      "\n",
      "Testing v7 on SVM/C ...\n",
      "Fitting 3 folds for each of 156 candidates, totalling 468 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   30.2s\n",
      "[Parallel(n_jobs=-1)]: Done 468 out of 468 | elapsed:   35.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'kernel': 'rbf', 'C': 1.2000000000000004, 'gamma': 0.1}\n",
      "MSE: 0.98046875\n",
      "\n",
      "Testing v7 on RandomForest ...\n",
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   27.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'n_estimators': 99}\n",
      "MSE: 0.975911458333\n",
      "\n",
      "Testing v7 on kNN ...\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "Params: {'n_neighbors': 4}\n",
      "MSE: 0.973958333333\n",
      "\n",
      "Testing v7 on SGD ...\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   10.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'max_iter': 600}\n",
      "MSE: 0.957682291667\n",
      "\n",
      "Testing v6 on AdaBoost ...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:   56.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'base_estimator': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=81, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), 'algorithm': 'SAMME'}\n",
      "MSE: 0.9609375\n",
      "\n",
      "Testing v6 on SVM/C ...\n",
      "Fitting 3 folds for each of 156 candidates, totalling 468 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   24.4s\n",
      "[Parallel(n_jobs=-1)]: Done 468 out of 468 | elapsed:   29.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'kernel': 'rbf', 'C': 3.8000000000000012, 'gamma': 0.1}\n",
      "MSE: 0.983072916667\n",
      "\n",
      "Testing v6 on RandomForest ...\n",
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   31.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'n_estimators': 78}\n",
      "MSE: 0.969401041667\n",
      "\n",
      "Testing v6 on kNN ...\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 out of  27 | elapsed:    2.0s remaining:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'n_neighbors': 1}\n",
      "MSE: 0.97265625\n",
      "\n",
      "Testing v6 on SGD ...\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   10.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'max_iter': 700}\n",
      "MSE: 0.948567708333\n",
      "\n",
      "Testing v4 on AdaBoost ...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'base_estimator': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=81, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), 'algorithm': 'SAMME'}\n",
      "MSE: 0.955078125\n",
      "\n",
      "Testing v4 on SVM/C ...\n",
      "Fitting 3 folds for each of 156 candidates, totalling 468 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   27.2s\n",
      "[Parallel(n_jobs=-1)]: Done 468 out of 468 | elapsed:   32.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'kernel': 'rbf', 'C': 1.7000000000000006, 'gamma': 0.1}\n",
      "MSE: 0.977864583333\n",
      "\n",
      "Testing v4 on RandomForest ...\n",
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   23.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'n_estimators': 83}\n",
      "MSE: 0.96484375\n",
      "\n",
      "Testing v4 on kNN ...\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 out of  27 | elapsed:    2.2s remaining:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'n_neighbors': 1}\n",
      "MSE: 0.968098958333\n",
      "\n",
      "Testing v4 on SGD ...\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   10.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'max_iter': 300}\n",
      "MSE: 0.948567708333\n",
      "\n",
      "Testing Cleaned+MinMaxScaled on AdaBoost ...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:   33.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'base_estimator': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=81, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), 'algorithm': 'SAMME'}\n",
      "MSE: 0.947916666667\n",
      "\n",
      "Testing Cleaned+MinMaxScaled on SVM/C ...\n",
      "Fitting 3 folds for each of 156 candidates, totalling 468 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   15.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'kernel': 'linear', 'C': 3.4500000000000011, 'gamma': 0.1}\n",
      "MSE: 0.96484375\n",
      "\n",
      "Testing Cleaned+MinMaxScaled on RandomForest ...\n",
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 468 out of 468 | elapsed:   18.7s finished\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   43.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'n_estimators': 72}\n",
      "MSE: 0.951171875\n",
      "\n",
      "Testing Cleaned+MinMaxScaled on kNN ...\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 out of  27 | elapsed:    1.5s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'n_neighbors': 1}\n",
      "MSE: 0.956380208333\n",
      "\n",
      "Testing Cleaned+MinMaxScaled on SGD ...\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    9.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'max_iter': 500}\n",
      "MSE: 0.951822916667\n",
      "\n",
      "Testing Cleaned+Extended+MinMaxScaled on AdaBoost ...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'base_estimator': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=81, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), 'algorithm': 'SAMME'}\n",
      "MSE: 0.9609375\n",
      "\n",
      "Testing Cleaned+Extended+MinMaxScaled on SVM/C ...\n",
      "Fitting 3 folds for each of 156 candidates, totalling 468 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   28.9s\n",
      "[Parallel(n_jobs=-1)]: Done 468 out of 468 | elapsed:   35.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'kernel': 'rbf', 'C': 2.9000000000000008, 'gamma': 0.1}\n",
      "MSE: 0.981770833333\n",
      "\n",
      "Testing Cleaned+Extended+MinMaxScaled on RandomForest ...\n",
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   25.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'n_estimators': 93}\n",
      "MSE: 0.965494791667\n",
      "\n",
      "Testing Cleaned+Extended+MinMaxScaled on kNN ...\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "Params: {'n_neighbors': 3}\n",
      "MSE: 0.970052083333\n",
      "\n",
      "Testing Cleaned+Extended+MinMaxScaled on SGD ...\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   12.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'max_iter': 400}\n",
      "MSE: 0.950520833333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "\n",
    "datasets = [\n",
    "    ('v8', scaled_v8),\n",
    "    ('v7', scaled_v7),\n",
    "    ('v6', scaled_v6),\n",
    "    ('v4', scaled_v4),\n",
    "    ('Cleaned+MinMaxScaled', minmaxscaled),\n",
    "    ('Cleaned+Extended+MinMaxScaled', minmaxscaled_ext)\n",
    "]\n",
    "\n",
    "options = {\n",
    "    'AdaBoost': {\n",
    "        'base_estimator': [\n",
    "            svm.SVC(kernel='rbf', C=3.65, gamma=0.1),\n",
    "            RandomForestClassifier(n_estimators=81)\n",
    "        ],\n",
    "        'algorithm': ['SAMME']\n",
    "    },\n",
    "    'SVM/C': {\n",
    "        'kernel': ('linear', 'rbf'),\n",
    "        'C': np.arange(.1, 4.0, .05),\n",
    "        'gamma': [.1]\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'n_estimators': range(60, 100)\n",
    "    },\n",
    "    'kNN': {\n",
    "        'n_neighbors': range(2, 15)\n",
    "    },\n",
    "    'SGD': {\n",
    "        'max_iter': [300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "    }\n",
    "}\n",
    "\n",
    "classifiers = [\n",
    "    ('AdaBoost', AdaBoostClassifier),\n",
    "    ('SVM/C', svm.SVC),\n",
    "    ('RandomForest', RandomForestClassifier),\n",
    "    ('kNN', KNeighborsClassifier),\n",
    "    ('SGD', linear_model.SGDClassifier)\n",
    "]\n",
    "\n",
    "def search(classifiers, options, datasets, test_size, random_state):\n",
    "    results = {\n",
    "        'rank': [],\n",
    "        'classifier': [],\n",
    "        'options': [],\n",
    "        'dataset': [],\n",
    "        'score': []\n",
    "    }\n",
    "\n",
    "    for dataset in datasets:\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(dataset[1].iloc[:,:-1], dataset[1].iloc[:,-1],\\\n",
    "                                                            test_size=test_size, random_state=random_state)\n",
    "        \n",
    "        for classifier in classifiers:\n",
    "            name = classifier[0]\n",
    "            print 'Testing', dataset[0], 'on', name, '...'\n",
    "\n",
    "            model = GridSearchCV(classifier[1](), options[name], verbose=1, n_jobs=-1, cv=3)\n",
    "            model.fit(X_train, Y_train)\n",
    "            \n",
    "            print 'Params:', model.best_params_\n",
    "            print 'MSE:', model.best_score_\n",
    "            print\n",
    "            \n",
    "            results['rank'].append(0)\n",
    "            results['classifier'].append(name)\n",
    "            results['options'].append(str(model.best_params_))\n",
    "            results['dataset'].append(dataset[0])\n",
    "            results['score'].append(model.best_score_)\n",
    "\n",
    "    return results\n",
    "\n",
    "results = search(classifiers, options, datasets, .20, 123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing v8 on SVM/C ...\n",
      "Fitting 3 folds for each of 2964 candidates, totalling 8892 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:   57.2s\n",
      "[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed:  2.1min\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "\n",
    "datasets = [\n",
    "    ('v8', scaled_v8),\n",
    "    ('v7', scaled_v7),\n",
    "    ('v6', scaled_v6),\n",
    "    ('v4', scaled_v4),\n",
    "    ('Cleaned+MinMaxScaled', minmaxscaled),\n",
    "    ('Cleaned+Extended+MinMaxScaled', minmaxscaled_ext)\n",
    "]\n",
    "\n",
    "options = {\n",
    "    'SVM/C': {\n",
    "        'kernel': ['rbf'],\n",
    "        'C': np.arange(.1, 4.0, .05),\n",
    "        'gamma': np.arange(.1, 2.0, .05)\n",
    "    },\n",
    "    'kNN': {\n",
    "        'n_neighbors': range(2, 15)\n",
    "    }\n",
    "}\n",
    "\n",
    "classifiers = [\n",
    "    ('SVM/C', svm.SVC),\n",
    "    ('kNN', KNeighborsClassifier)\n",
    "]\n",
    "\n",
    "def search(classifiers, options, datasets, test_size, random_state):\n",
    "    results = {\n",
    "        'rank': [],\n",
    "        'classifier': [],\n",
    "        'options': [],\n",
    "        'dataset': [],\n",
    "        'score': []\n",
    "    }\n",
    "\n",
    "    for dataset in datasets:\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(dataset[1].iloc[:,:-1], dataset[1].iloc[:,-1],\\\n",
    "                                                            test_size=test_size, random_state=random_state)\n",
    "        \n",
    "        for classifier in classifiers:\n",
    "            name = classifier[0]\n",
    "            print 'Testing', dataset[0], 'on', name, '...'\n",
    "\n",
    "            model = GridSearchCV(classifier[1](), options[name], verbose=1, n_jobs=-1, cv=3)\n",
    "            model.fit(X_train, Y_train)\n",
    "            \n",
    "            print 'Params:', model.best_params_\n",
    "            print 'MSE:', model.best_score_\n",
    "            print\n",
    "            \n",
    "            results['rank'].append(0)\n",
    "            results['classifier'].append(name)\n",
    "            results['options'].append(str(model.best_params_))\n",
    "            results['dataset'].append(dataset[0])\n",
    "            results['score'].append(model.best_score_)\n",
    "\n",
    "    return results\n",
    "\n",
    "results = search(classifiers, options, datasets, .20, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results).sort_values(['score'], ascending=[False])\n",
    "results_df['rank'] = pd.Series(range(1, len(results_df) + 1), index=results_df.index)\n",
    "results_df[['rank', 'classifier', 'options', 'dataset', 'score']].to_csv('../classifiers/results_20181110151634_20_0.csv', sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy', 0.99479166666666663)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "best = svm.SVC(kernel='rbf', C=3.65, gamma=0.1)\n",
    "X_train, X_test, Y_train, Y_test = split(scaled_v8, .20)\n",
    "Y_pred = best.fit(X_train, Y_train).predict(X_test)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes):\n",
    "#     print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Greens)\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "\n",
    "print('Accuracy', best.score(X_test, Y_test))\n",
    "plot_confusion_matrix(cnf_matrix, classes=range(0,10))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
