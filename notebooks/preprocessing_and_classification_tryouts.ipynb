{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing & Classification Try-Outs\n",
    "\n",
    "Here we try out different datasets we compiled, normalizers and classifiers that are available and try to determine the best combination.\n",
    "\n",
    "## Datasets\n",
    "\n",
    "Name | Description | Pixel Count Grid Size | Automatic Feature Selection | Better Hole Detection | File\n",
    "--- | --- | --- | --- | --- | ---\n",
    "Full | All (at that time) features, not cleaned. | 4 | N | N | `dataset.csv`\n",
    "Cleaned | Most features (manually chosen). | 4 | N | N | `dataset-clean-manual.csv`\n",
    "Cleaned+Extended | Most features and with more detail pixel count. | 8 | N | N | `dataset-clean-matrix.csv`\n",
    "Cleaned+CleanExtended | Most features but with empy pixel counts removed. | 8 | N | N | `dataset-clean-clean-matrix.csv`\n",
    "v4 | ? | 8 | N | N | `dataset-v4.csv`\n",
    "v5 | Mixed with resized MNIST dataset. | 8 | N | N | `mnist.csv`\n",
    "v6 | Uses automatic feature selection. | 8 | Y | N | `dataset-v6.csv`\n",
    "v7 | All features (including blob width), automatic feature selection. | 8 | Y | Y | `dataset-v7.csv`\n",
    "v8 | Includes all features and better hole detection. | 8 | N | Y | `dataset-v8.csv`\n",
    "\n",
    "## Normalizers\n",
    "\n",
    "- MinMax\n",
    "- Robust\n",
    "- QuartileTransformed\n",
    "\n",
    "## Classifier\n",
    "\n",
    "rank | classifier | options | dataset | score\n",
    "--- | --- | --- | --- | ---\n",
    "1 | SVM/C | `{'kernel': 'rbf', 'C': 3.75, 'gamma': 0.10}` | v8 | `0.987630208333`\n",
    "2 | SVM/C | `{'kernel': 'rbf', 'C': 3.85, 'gamma': 0.10}` | v7 | `0.986328125000`\n",
    "3 | SVM/C | `{'kernel': 'rbf', 'C': 3.70, 'gamma': 0.15}` | v6 | `0.984375000000`\n",
    "4 | SVM/C | `{'kernel': 'rbf', 'C': 3.65, 'gamma': 0.15}` | Cleaned+Extended+MinMaxScaled | `0.980468750000`\n",
    "5 | SVM/C | `{'kernel': 'rbf', 'C': 2.55, 'gamma': 0.15}` | v4 | `0.977864583333`\n",
    "6 | kNN | `{'n_neighbors': 3}` | v8 | `0.973958333333`\n",
    "7 | kNN | `{'n_neighbors': 4}` | v7 | `0.970703125000`\n",
    "8 | kNN | `{'n_neighbors': 3}` | v6 | `0.968750000000`\n",
    "9 | kNN | `{'n_neighbors': 3}` | Cleaned+Extended+MinMaxScaled | `0.967447916667`\n",
    "10 | kNN | `{'n_neighbors': 5}` | v4 | `0.964192708333`\n",
    "11 | SVM/C | `{'kernel': 'rbf', 'C': 3.80, 'gamma': 0.95}` | Cleaned+MinMaxScaled | `0.962890625000`\n",
    "12 | kNN | `{'n_neighbors': 3}` | Cleaned+MinMaxScaled | `0.945312500000`\n",
    "\n",
    "Source: `classifiers/results_20181110151634_20_0.csv` (Train test split 20%, random state `0`)\n",
    "\n",
    "- SVM/C\n",
    "- kNN\n",
    "- RandomForest\n",
    "- AdaBoost\n",
    "- SGD\n",
    "\n",
    "## Winner\n",
    "\n",
    "Classifier SVM/C `kernel='rbf', C=3.75, gamma=0.1` with dataset v8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS AND NOTEBOOK SETUP\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# Normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "\n",
    "# Helpers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING OUR DATASET\n",
    "data_full = pd.read_csv('../dataset-numpy/dataset.csv')\n",
    "data_clean_manual = pd.read_csv('../dataset-numpy/dataset-clean-manual.csv')\n",
    "data_ext_clean_manual = pd.read_csv('../dataset-numpy/dataset-extended-clean-manual.csv')\n",
    "data_v4 = pd.read_csv('../dataset-numpy/dataset-v4.csv')\n",
    "data_v6 = pd.read_csv('../dataset-numpy/dataset-v6.csv')\n",
    "data_v7 = pd.read_csv('../dataset-numpy/dataset-v7.csv')\n",
    "data_v8 = pd.read_csv('../dataset-numpy/dataset-v8.csv') # more features, but all columns\n",
    "data_v9 = pd.read_csv('../dataset-numpy/dataset-v9.csv') # better hole detection version of v7?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "less_columns = data_clean_manual.columns.values\n",
    "columns_v4 = data_v4.columns.values\n",
    "columns_v6 = data_v6.columns.values\n",
    "columns_v7 = data_v7.columns.values\n",
    "columns_v8 = data_v8.columns.values\n",
    "columns_to_not_normalize = ['label']\n",
    "\n",
    "columns_v4_to_normalize = [c for c in columns_v4 if not c in columns_to_not_normalize]\n",
    "columns_v6_to_normalize = [c for c in columns_v6 if not c in columns_to_not_normalize]\n",
    "columns_v7_to_normalize = [c for c in columns_v7 if not c in columns_to_not_normalize]\n",
    "columns_v8_to_normalize = [c for c in columns_v8 if not c in columns_to_not_normalize]\n",
    "less_columns_to_normalize = [c for c in less_columns if not c in columns_to_not_normalize]\n",
    "        \n",
    "def scale(data, scaler, columns):\n",
    "    return pd.DataFrame(scaler.fit_transform(data[columns]), columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 24) (1920, 72) (1920, 60) (1920, 56) (1920, 58) (1920, 79)\n"
     ]
    }
   ],
   "source": [
    "minmaxscaled = data_clean_manual.copy()\n",
    "minmaxscaled[less_columns_to_normalize] = scale(data_clean_manual, MinMaxScaler(), less_columns_to_normalize)\n",
    "\n",
    "minmaxscaled_ext = data_ext_clean_manual.copy()\n",
    "minmaxscaled_ext[columns_v4_to_normalize] = scale(data_ext_clean_manual, MinMaxScaler(), columns_v4_to_normalize)\n",
    "\n",
    "scaled_v4 = data_v4.copy()\n",
    "scaled_v4[columns_v4_to_normalize] = scale(data_v4, MinMaxScaler(), columns_v4_to_normalize)\n",
    "\n",
    "scaled_v6 = data_v6.copy()\n",
    "scaled_v6[columns_v6_to_normalize] = scale(data_v6, MinMaxScaler(), columns_v6_to_normalize)\n",
    "\n",
    "scaled_v7 = data_v7.copy()\n",
    "scaled_v7[columns_v7_to_normalize] = scale(data_v7, MinMaxScaler(), columns_v7_to_normalize)\n",
    "\n",
    "scaled_v8 = data_v8.copy()\n",
    "scaled_v8[columns_v8_to_normalize] = scale(data_v8, MinMaxScaler(), columns_v8_to_normalize)\n",
    "\n",
    "print minmaxscaled.shape, minmaxscaled_ext.shape, scaled_v4.shape, scaled_v6.shape, scaled_v7.shape, scaled_v8.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ~~RobustScaler~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>contours</th>\n",
       "      <th>radius</th>\n",
       "      <th>hull_radius</th>\n",
       "      <th>centroid_x</th>\n",
       "      <th>centroid_y</th>\n",
       "      <th>weight_0_0</th>\n",
       "      <th>weight_0_1</th>\n",
       "      <th>weight_0_2</th>\n",
       "      <th>weight_0_3</th>\n",
       "      <th>...</th>\n",
       "      <th>weight_2_0</th>\n",
       "      <th>weight_2_1</th>\n",
       "      <th>weight_2_2</th>\n",
       "      <th>weight_2_3</th>\n",
       "      <th>weight_3_0</th>\n",
       "      <th>weight_3_1</th>\n",
       "      <th>weight_3_2</th>\n",
       "      <th>weight_3_3</th>\n",
       "      <th>num_holes</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1.920000e+03</td>\n",
       "      <td>1.920000e+03</td>\n",
       "      <td>1.920000e+03</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.196993</td>\n",
       "      <td>0.079340</td>\n",
       "      <td>1.017201e-01</td>\n",
       "      <td>4.136941e-02</td>\n",
       "      <td>4.102775e-02</td>\n",
       "      <td>0.038119</td>\n",
       "      <td>0.580078</td>\n",
       "      <td>-0.179688</td>\n",
       "      <td>-0.073462</td>\n",
       "      <td>1.016016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.585851</td>\n",
       "      <td>-0.021638</td>\n",
       "      <td>-0.052961</td>\n",
       "      <td>0.140814</td>\n",
       "      <td>1.218229</td>\n",
       "      <td>-0.134961</td>\n",
       "      <td>-0.238310</td>\n",
       "      <td>0.473958</td>\n",
       "      <td>0.379688</td>\n",
       "      <td>4.532813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.822303</td>\n",
       "      <td>0.728725</td>\n",
       "      <td>7.284580e-01</td>\n",
       "      <td>7.250003e-01</td>\n",
       "      <td>7.986912e-01</td>\n",
       "      <td>0.834985</td>\n",
       "      <td>0.905983</td>\n",
       "      <td>0.850967</td>\n",
       "      <td>0.740222</td>\n",
       "      <td>2.110030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.948393</td>\n",
       "      <td>0.583812</td>\n",
       "      <td>0.749764</td>\n",
       "      <td>0.629568</td>\n",
       "      <td>2.723832</td>\n",
       "      <td>0.889798</td>\n",
       "      <td>0.911930</td>\n",
       "      <td>0.996559</td>\n",
       "      <td>0.584767</td>\n",
       "      <td>2.868122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.493902</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-1.691895e+00</td>\n",
       "      <td>-1.840064e+00</td>\n",
       "      <td>-2.651279e+00</td>\n",
       "      <td>-2.105159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.812500</td>\n",
       "      <td>-1.904762</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.969697</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-0.454545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.500000</td>\n",
       "      <td>-2.444444</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.384146</td>\n",
       "      <td>-0.416667</td>\n",
       "      <td>-4.476046e-01</td>\n",
       "      <td>-4.893416e-01</td>\n",
       "      <td>-4.820904e-01</td>\n",
       "      <td>-0.526539</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.562500</td>\n",
       "      <td>-0.523810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.515152</td>\n",
       "      <td>-0.526316</td>\n",
       "      <td>-0.454545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.562500</td>\n",
       "      <td>-0.611111</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.274827e-16</td>\n",
       "      <td>-7.901665e-16</td>\n",
       "      <td>5.943054e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.615854</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>5.523954e-01</td>\n",
       "      <td>5.106584e-01</td>\n",
       "      <td>5.179096e-01</td>\n",
       "      <td>0.473461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.884146</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>2.251112e+00</td>\n",
       "      <td>2.517077e+00</td>\n",
       "      <td>3.086590e+00</td>\n",
       "      <td>2.477812</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1.187500</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.368421</td>\n",
       "      <td>2.363636</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              area     contours        radius   hull_radius    centroid_x  \\\n",
       "count  1920.000000  1920.000000  1.920000e+03  1.920000e+03  1.920000e+03   \n",
       "mean      0.196993     0.079340  1.017201e-01  4.136941e-02  4.102775e-02   \n",
       "std       0.822303     0.728725  7.284580e-01  7.250003e-01  7.986912e-01   \n",
       "min      -1.493902    -2.000000 -1.691895e+00 -1.840064e+00 -2.651279e+00   \n",
       "25%      -0.384146    -0.416667 -4.476046e-01 -4.893416e-01 -4.820904e-01   \n",
       "50%       0.000000     0.000000  7.274827e-16 -7.901665e-16  5.943054e-16   \n",
       "75%       0.615854     0.583333  5.523954e-01  5.106584e-01  5.179096e-01   \n",
       "max       2.884146     3.666667  2.251112e+00  2.517077e+00  3.086590e+00   \n",
       "\n",
       "        centroid_y   weight_0_0   weight_0_1   weight_0_2   weight_0_3  \\\n",
       "count  1920.000000  1920.000000  1920.000000  1920.000000  1920.000000   \n",
       "mean      0.038119     0.580078    -0.179688    -0.073462     1.016016   \n",
       "std       0.834985     0.905983     0.850967     0.740222     2.110030   \n",
       "min      -2.105159     0.000000    -2.812500    -1.904762     0.000000   \n",
       "25%      -0.526539     0.000000    -0.562500    -0.523810     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.473461     1.000000     0.437500     0.476190     1.000000   \n",
       "max       2.477812     5.500000     1.187500     1.142857    15.500000   \n",
       "\n",
       "          ...        weight_2_0   weight_2_1   weight_2_2   weight_2_3  \\\n",
       "count     ...       1920.000000  1920.000000  1920.000000  1920.000000   \n",
       "mean      ...          0.585851    -0.021638    -0.052961     0.140814   \n",
       "std       ...          0.948393     0.583812     0.749764     0.629568   \n",
       "min       ...          0.000000    -0.969697    -2.000000    -0.454545   \n",
       "25%       ...          0.000000    -0.515152    -0.526316    -0.454545   \n",
       "50%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "75%       ...          1.000000     0.484848     0.473684     0.545455   \n",
       "max       ...          6.500000     0.969697     1.368421     2.363636   \n",
       "\n",
       "        weight_3_0   weight_3_1   weight_3_2   weight_3_3    num_holes  \\\n",
       "count  1920.000000  1920.000000  1920.000000  1920.000000  1920.000000   \n",
       "mean      1.218229    -0.134961    -0.238310     0.473958     0.379688   \n",
       "std       2.723832     0.889798     0.911930     0.996559     0.584767   \n",
       "min       0.000000    -2.500000    -2.444444    -0.200000     0.000000   \n",
       "25%       0.000000    -0.562500    -0.611111    -0.200000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     0.437500     0.388889     0.800000     1.000000   \n",
       "max      29.000000     1.500000     1.111111     5.300000     2.000000   \n",
       "\n",
       "             label  \n",
       "count  1920.000000  \n",
       "mean      4.532813  \n",
       "std       2.868122  \n",
       "min       0.000000  \n",
       "25%       2.000000  \n",
       "50%       5.000000  \n",
       "75%       7.000000  \n",
       "max       9.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robustscaled = data_clean_manual.copy()\n",
    "robustscaled[less_columns_to_normalize] = scale(data_clean_manual, RobustScaler(), less_columns_to_normalize)\n",
    "robustscaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ~~QuantileTransformer~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>contours</th>\n",
       "      <th>radius</th>\n",
       "      <th>hull_radius</th>\n",
       "      <th>centroid_x</th>\n",
       "      <th>centroid_y</th>\n",
       "      <th>weight_0_0</th>\n",
       "      <th>weight_0_1</th>\n",
       "      <th>weight_0_2</th>\n",
       "      <th>weight_0_3</th>\n",
       "      <th>...</th>\n",
       "      <th>weight_2_0</th>\n",
       "      <th>weight_2_1</th>\n",
       "      <th>weight_2_2</th>\n",
       "      <th>weight_2_3</th>\n",
       "      <th>weight_3_0</th>\n",
       "      <th>weight_3_1</th>\n",
       "      <th>weight_3_2</th>\n",
       "      <th>weight_3_3</th>\n",
       "      <th>num_holes</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.920000e+03</td>\n",
       "      <td>1.920000e+03</td>\n",
       "      <td>1.920000e+03</td>\n",
       "      <td>1.920000e+03</td>\n",
       "      <td>1.920000e+03</td>\n",
       "      <td>1.920000e+03</td>\n",
       "      <td>1.920000e+03</td>\n",
       "      <td>1.920000e+03</td>\n",
       "      <td>1.920000e+03</td>\n",
       "      <td>1.920000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>1.920000e+03</td>\n",
       "      <td>1.920000e+03</td>\n",
       "      <td>1.920000e+03</td>\n",
       "      <td>1.920000e+03</td>\n",
       "      <td>1.920000e+03</td>\n",
       "      <td>1.920000e+03</td>\n",
       "      <td>1.920000e+03</td>\n",
       "      <td>1.920000e+03</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.999974e-01</td>\n",
       "      <td>5.000066e-01</td>\n",
       "      <td>4.999996e-01</td>\n",
       "      <td>5.000034e-01</td>\n",
       "      <td>4.999984e-01</td>\n",
       "      <td>4.999982e-01</td>\n",
       "      <td>3.476723e-01</td>\n",
       "      <td>5.000201e-01</td>\n",
       "      <td>4.999338e-01</td>\n",
       "      <td>3.040906e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.541981e-01</td>\n",
       "      <td>4.985454e-01</td>\n",
       "      <td>5.000751e-01</td>\n",
       "      <td>4.382782e-01</td>\n",
       "      <td>2.425205e-01</td>\n",
       "      <td>4.997604e-01</td>\n",
       "      <td>5.000615e-01</td>\n",
       "      <td>3.952468e-01</td>\n",
       "      <td>0.379688</td>\n",
       "      <td>4.532813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.888959e-01</td>\n",
       "      <td>2.887092e-01</td>\n",
       "      <td>2.888972e-01</td>\n",
       "      <td>2.889019e-01</td>\n",
       "      <td>2.888986e-01</td>\n",
       "      <td>2.888992e-01</td>\n",
       "      <td>3.955703e-01</td>\n",
       "      <td>2.889265e-01</td>\n",
       "      <td>2.891776e-01</td>\n",
       "      <td>3.990423e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.943233e-01</td>\n",
       "      <td>2.916285e-01</td>\n",
       "      <td>2.889566e-01</td>\n",
       "      <td>3.562232e-01</td>\n",
       "      <td>3.891705e-01</td>\n",
       "      <td>2.893259e-01</td>\n",
       "      <td>2.903445e-01</td>\n",
       "      <td>3.811212e-01</td>\n",
       "      <td>0.584767</td>\n",
       "      <td>2.868122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.502503e-01</td>\n",
       "      <td>2.577578e-01</td>\n",
       "      <td>2.497667e-01</td>\n",
       "      <td>2.500801e-01</td>\n",
       "      <td>2.501045e-01</td>\n",
       "      <td>2.499021e-01</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>2.537538e-01</td>\n",
       "      <td>2.567568e-01</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>2.512513e-01</td>\n",
       "      <td>2.532533e-01</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>2.422422e-01</td>\n",
       "      <td>2.517518e-01</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.010010e-01</td>\n",
       "      <td>4.809810e-01</td>\n",
       "      <td>4.998480e-01</td>\n",
       "      <td>5.000105e-01</td>\n",
       "      <td>4.999102e-01</td>\n",
       "      <td>4.999490e-01</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>5.080080e-01</td>\n",
       "      <td>4.894895e-01</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>5.010010e-01</td>\n",
       "      <td>4.889890e-01</td>\n",
       "      <td>5.055055e-01</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>5.100100e-01</td>\n",
       "      <td>5.025025e-01</td>\n",
       "      <td>5.200200e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.507508e-01</td>\n",
       "      <td>7.597598e-01</td>\n",
       "      <td>7.500140e-01</td>\n",
       "      <td>7.501820e-01</td>\n",
       "      <td>7.502810e-01</td>\n",
       "      <td>7.502003e-01</td>\n",
       "      <td>7.677678e-01</td>\n",
       "      <td>7.492492e-01</td>\n",
       "      <td>7.472472e-01</td>\n",
       "      <td>7.477477e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>7.612613e-01</td>\n",
       "      <td>7.492492e-01</td>\n",
       "      <td>7.447447e-01</td>\n",
       "      <td>7.392392e-01</td>\n",
       "      <td>7.467467e-01</td>\n",
       "      <td>7.482482e-01</td>\n",
       "      <td>7.567568e-01</td>\n",
       "      <td>7.462462e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               area      contours        radius   hull_radius    centroid_x  \\\n",
       "count  1.920000e+03  1.920000e+03  1.920000e+03  1.920000e+03  1.920000e+03   \n",
       "mean   4.999974e-01  5.000066e-01  4.999996e-01  5.000034e-01  4.999984e-01   \n",
       "std    2.888959e-01  2.887092e-01  2.888972e-01  2.889019e-01  2.888986e-01   \n",
       "min    1.000000e-07  1.000000e-07  1.000000e-07  1.000000e-07  1.000000e-07   \n",
       "25%    2.502503e-01  2.577578e-01  2.497667e-01  2.500801e-01  2.501045e-01   \n",
       "50%    5.010010e-01  4.809810e-01  4.998480e-01  5.000105e-01  4.999102e-01   \n",
       "75%    7.507508e-01  7.597598e-01  7.500140e-01  7.501820e-01  7.502810e-01   \n",
       "max    9.999999e-01  9.999999e-01  9.999999e-01  9.999999e-01  9.999999e-01   \n",
       "\n",
       "         centroid_y    weight_0_0    weight_0_1    weight_0_2    weight_0_3  \\\n",
       "count  1.920000e+03  1.920000e+03  1.920000e+03  1.920000e+03  1.920000e+03   \n",
       "mean   4.999982e-01  3.476723e-01  5.000201e-01  4.999338e-01  3.040906e-01   \n",
       "std    2.888992e-01  3.955703e-01  2.889265e-01  2.891776e-01  3.990423e-01   \n",
       "min    1.000000e-07  1.000000e-07  1.000000e-07  1.000000e-07  1.000000e-07   \n",
       "25%    2.499021e-01  1.000000e-07  2.537538e-01  2.567568e-01  1.000000e-07   \n",
       "50%    4.999490e-01  1.000000e-07  5.080080e-01  4.894895e-01  1.000000e-07   \n",
       "75%    7.502003e-01  7.677678e-01  7.492492e-01  7.472472e-01  7.477477e-01   \n",
       "max    9.999999e-01  9.999999e-01  9.999999e-01  9.999999e-01  9.999999e-01   \n",
       "\n",
       "          ...         weight_2_0    weight_2_1    weight_2_2    weight_2_3  \\\n",
       "count     ...       1.920000e+03  1.920000e+03  1.920000e+03  1.920000e+03   \n",
       "mean      ...       3.541981e-01  4.985454e-01  5.000751e-01  4.382782e-01   \n",
       "std       ...       3.943233e-01  2.916285e-01  2.889566e-01  3.562232e-01   \n",
       "min       ...       1.000000e-07  1.000000e-07  1.000000e-07  1.000000e-07   \n",
       "25%       ...       1.000000e-07  2.512513e-01  2.532533e-01  1.000000e-07   \n",
       "50%       ...       1.000000e-07  5.010010e-01  4.889890e-01  5.055055e-01   \n",
       "75%       ...       7.612613e-01  7.492492e-01  7.447447e-01  7.392392e-01   \n",
       "max       ...       9.999999e-01  9.999999e-01  9.999999e-01  9.999999e-01   \n",
       "\n",
       "         weight_3_0    weight_3_1    weight_3_2    weight_3_3    num_holes  \\\n",
       "count  1.920000e+03  1.920000e+03  1.920000e+03  1.920000e+03  1920.000000   \n",
       "mean   2.425205e-01  4.997604e-01  5.000615e-01  3.952468e-01     0.379688   \n",
       "std    3.891705e-01  2.893259e-01  2.903445e-01  3.811212e-01     0.584767   \n",
       "min    1.000000e-07  1.000000e-07  1.000000e-07  1.000000e-07     0.000000   \n",
       "25%    1.000000e-07  2.422422e-01  2.517518e-01  1.000000e-07     0.000000   \n",
       "50%    1.000000e-07  5.100100e-01  5.025025e-01  5.200200e-01     0.000000   \n",
       "75%    7.467467e-01  7.482482e-01  7.567568e-01  7.462462e-01     1.000000   \n",
       "max    9.999999e-01  9.999999e-01  9.999999e-01  9.999999e-01     2.000000   \n",
       "\n",
       "             label  \n",
       "count  1920.000000  \n",
       "mean      4.532813  \n",
       "std       2.868122  \n",
       "min       0.000000  \n",
       "25%       2.000000  \n",
       "50%       5.000000  \n",
       "75%       7.000000  \n",
       "max       9.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantiletransformed = data_clean_manual.copy()\n",
    "quantiletransformed[less_columns_to_normalize] = scale(data_clean_manual, QuantileTransformer(), less_columns_to_normalize)\n",
    "quantiletransformed.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data, ratio, random_state=None):\n",
    "    return train_test_split(data.iloc[:,:-1], data.iloc[:,-1], test_size=ratio, random_state=random_state)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = split(scaled_v8, .20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Random Forest Classifier\n",
    "\n",
    "Trying different numbers of estimators on the same split to determine the best setiings for that set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_E: 2 Score: 0.763020833333\n",
      "N_E: 3 Score: 0.84375\n",
      "N_E: 4 Score: 0.864583333333\n",
      "N_E: 5 Score: 0.890625\n",
      "N_E: 6 Score: 0.901041666667\n",
      "N_E: 7 Score: 0.903645833333\n",
      "N_E: 8 Score: 0.921875\n",
      "N_E: 9 Score: 0.932291666667\n",
      "N_E: 10 Score: 0.940104166667\n",
      "N_E: 11 Score: 0.9453125\n",
      "N_E: 12 Score: 0.953125\n",
      "N_E: 13 Score: 0.955729166667\n",
      "N_E: 16 Score: 0.963541666667\n",
      "N_E: 17 Score: 0.966145833333\n",
      "N_E: 19 Score: 0.96875\n",
      "N_E: 38 Score: 0.971354166667\n",
      "N_E: 39 Score: 0.973958333333\n",
      "N_E: 62 Score: 0.9765625\n",
      "N_E: 91 Score: 0.979166666667\n",
      "Top: (91, 0.97916666666666663)\n"
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST\n",
    "top_rf = (2, 0.0)\n",
    "for n_e in range(2, 101):\n",
    "    rf = RandomForestClassifier(n_estimators=n_e, oob_score=True, random_state=123456)\n",
    "    rf.fit(X_train, Y_train)\n",
    "    score = rf.score(X_test, Y_test)\n",
    "    if score > top_rf[1]:\n",
    "        top_rf = (n_e, score)\n",
    "        print 'N_E:', n_e, 'Score:', score\n",
    "print 'Top:', top_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Support Vector Machine\n",
    "\n",
    "100 x random train test splits. Taking the min, max and mean of the results to compare options and datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Score: 0.963541666667\n",
      "Max Score: 0.997395833333\n",
      "Mean Score: 0.985299479167\n",
      "\n",
      "Min Score: 0.96875\n",
      "Max Score: 0.997395833333\n",
      "Mean Score: 0.984153645833\n",
      "\n",
      "Min Score: 0.9609375\n",
      "Max Score: 1.0\n",
      "Mean Score: 0.983411458333\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "ITERS = 200\n",
    "scores = np.zeros((ITERS))\n",
    "\n",
    "for i in range(ITERS):\n",
    "    X_train, X_test, Y_train, Y_test = split(scaled_v8, .20)\n",
    "    svc = svm.SVC(kernel='rbf', C=3.75, gamma=0.1)\n",
    "    svc.fit(X_train, Y_train)\n",
    "    scores[i] = svc.score(X_test, Y_test)\n",
    "\n",
    "print 'Min Score:', scores.min()\n",
    "print 'Max Score:', scores.max()\n",
    "print 'Mean Score:', scores.mean()\n",
    "\n",
    "print\n",
    "\n",
    "for i in range(ITERS):\n",
    "    X_train, X_test, Y_train, Y_test = split(scaled_v7, .20)\n",
    "    svc = svm.SVC(kernel='rbf', C=3.85, gamma=0.1)\n",
    "    svc.fit(X_train, Y_train)\n",
    "    scores[i] = svc.score(X_test, Y_test)\n",
    "\n",
    "print 'Min Score:', scores.min()\n",
    "print 'Max Score:', scores.max()\n",
    "print 'Mean Score:', scores.mean()\n",
    "\n",
    "print\n",
    "\n",
    "for i in range(ITERS):\n",
    "    X_train, X_test, Y_train, Y_test = split(scaled_v6, .20)\n",
    "    svc = svm.SVC(kernel='rbf', C=3.70, gamma=0.15)\n",
    "    svc.fit(X_train, Y_train)\n",
    "    scores[i] = svc.score(X_test, Y_test)\n",
    "\n",
    "print 'Min Score:', scores.min()\n",
    "print 'Max Score:', scores.max()\n",
    "print 'Mean Score:', scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating on unseen data using KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1728, 78) (192, 78) (1728,) (192,)\n"
     ]
    }
   ],
   "source": [
    "DATASET = scaled_v8\n",
    "X, X_validation, Y, Y_validation = split(DATASET, .1, random_state=1)\n",
    "\n",
    "print X.shape, X_validation.shape, Y.shape, Y_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.982658959538\n",
      "Score: 0.976878612717\n",
      "Score: 0.971098265896\n",
      "Score: 0.988439306358\n",
      "Score: 0.982658959538\n",
      "Score: 0.994219653179\n",
      "Score: 0.976878612717\n",
      "Score: 0.982658959538\n",
      "Score: 0.970930232558\n",
      "Score: 1.0\n",
      "\n",
      "Score:  0.994791666667\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "svc = svm.SVC(kernel='rbf', C=3.65, gamma=0.1)\n",
    "\n",
    "for train, test in kf.split(X):\n",
    "    X_train, X_test, Y_train, Y_test = X.iloc[train], X.iloc[test], Y.iloc[train], Y.iloc[test]\n",
    "    # Testing on train/test data\n",
    "    svc.fit(X_train, Y_train)\n",
    "    print 'Score:', svc.score(X_test, Y_test)\n",
    "\n",
    "print\n",
    "# Validating on unseen validation data\n",
    "print 'Score: ', svc.score(X_validation, Y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the optimal C and Gamma for RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = split(scaled_v8, .20)\n",
    "\n",
    "Gs = np.arange(.1, 1, .05)\n",
    "Cs = np.arange(1.5, 4, .05)\n",
    "\n",
    "steps = len(Gs) * len(Cs)\n",
    "scores = np.array([np.zeros((3)) for s in range(steps)])\n",
    "index = 0\n",
    "top = [.1, .1, 0]\n",
    "\n",
    "for g in Gs:\n",
    "    for c in Cs:\n",
    "        print('%d / %d' % (index, steps))\n",
    "        svc = svm.SVC(kernel='rbf', C=c, gamma=g)\n",
    "        svc.fit(X_train, Y_train)\n",
    "        score = svc.score(X_test, Y_test)\n",
    "        scores[index] = np.array([c, g, score])\n",
    "        if score > top[2]:\n",
    "            top = scores[index]\n",
    "            print top\n",
    "        index += 1\n",
    "\n",
    "print 'Top:', top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npscores = np.array(scores[:300])\n",
    "plt.scatter(range(len(npscores)), npscores[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = linear_model.SGDClassifier(max_iter=200)\n",
    "sgd.fit(X_train, Y_train)\n",
    "score = sgd.score(X_test, Y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, Y_train)\n",
    "score = knn.score(X_test, Y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Ns = range(3, 30)\n",
    "scores = np.zeros((len(Ns)))\n",
    "index = 0\n",
    "top = (3, 0)\n",
    "for n in Ns:\n",
    "    print('%d / %d (%d)' % (index, len(Ns)-1, n))\n",
    "    knn = KNeighborsClassifier(n_neighbors=n)\n",
    "    knn.fit(X_train, Y_train)\n",
    "    score = knn.score(X_test, Y_test)\n",
    "    scores[index] = score\n",
    "    if score > top[1]:\n",
    "        top = (n, score)\n",
    "    index += 1\n",
    "\n",
    "print('Top:', top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Automation\n",
    "\n",
    "We wrote a custom loop to test all combinations of datasets and classifiers with gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(classifiers, options, datasets, test_size, random_state):\n",
    "    results = {\n",
    "        'rank': [],\n",
    "        'classifier': [],\n",
    "        'options': [],\n",
    "        'dataset': [],\n",
    "        'score': []\n",
    "    }\n",
    "\n",
    "    for dataset in datasets:\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(dataset[1].iloc[:,:-1], dataset[1].iloc[:,-1],\\\n",
    "                                                            test_size=test_size, random_state=random_state)\n",
    "        \n",
    "        for classifier in classifiers:\n",
    "            name = classifier[0]\n",
    "            print 'Testing', dataset[0], 'on', name, '...'\n",
    "\n",
    "            model = GridSearchCV(classifier[1](), options[name], verbose=1, n_jobs=-1, cv=3)\n",
    "            model.fit(X_train, Y_train)\n",
    "            \n",
    "            print 'Params:', model.best_params_\n",
    "            print 'MSE:', model.best_score_\n",
    "            print\n",
    "            \n",
    "            results['rank'].append(0)\n",
    "            results['classifier'].append(name)\n",
    "            results['options'].append(str(model.best_params_))\n",
    "            results['dataset'].append(dataset[0])\n",
    "            results['score'].append(model.best_score_)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test every combination to get an idea of the best classifier, options and dataset within a reasonable of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    ('v8', scaled_v8),\n",
    "    ('v7', scaled_v7),\n",
    "    ('v6', scaled_v6),\n",
    "    ('v4', scaled_v4),\n",
    "    ('Cleaned+MinMaxScaled', minmaxscaled),\n",
    "    ('Cleaned+Extended+MinMaxScaled', minmaxscaled_ext)\n",
    "]\n",
    "\n",
    "options = {\n",
    "    'AdaBoost': {\n",
    "        'base_estimator': [\n",
    "            svm.SVC(kernel='rbf', C=3.65, gamma=0.1),\n",
    "            RandomForestClassifier(n_estimators=81)\n",
    "        ],\n",
    "        'algorithm': ['SAMME']\n",
    "    },\n",
    "    'SVM/C': {\n",
    "        'kernel': ('linear', 'rbf'),\n",
    "        'C': np.arange(.1, 4.0, .5),\n",
    "        'gamma': [.1]\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'n_estimators': range(60, 100)\n",
    "    },\n",
    "    'kNN': {\n",
    "        'n_neighbors': range(2, 15)\n",
    "    },\n",
    "    'SGD': {\n",
    "        'max_iter': [300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "    }\n",
    "}\n",
    "\n",
    "classifiers = [\n",
    "    ('AdaBoost', AdaBoostClassifier),\n",
    "    ('SVM/C', svm.SVC),\n",
    "    ('RandomForest', RandomForestClassifier),\n",
    "    ('kNN', KNeighborsClassifier),\n",
    "    ('SGD', linear_model.SGDClassifier)\n",
    "]\n",
    "\n",
    "results = search(classifiers, options, datasets, .20, 123456)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used a more specific set of options with less classifiers to get the best options in a realistic amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    ('v8', scaled_v8),\n",
    "    ('v7', scaled_v7),\n",
    "    ('v6', scaled_v6),\n",
    "    ('v4', scaled_v4),\n",
    "    ('Cleaned+MinMaxScaled', minmaxscaled),\n",
    "    ('Cleaned+Extended+MinMaxScaled', minmaxscaled_ext)\n",
    "]\n",
    "\n",
    "options = {\n",
    "    'SVM/C': {\n",
    "        'kernel': ['rbf'],\n",
    "        'C': np.arange(.1, 4.0, .05),\n",
    "        'gamma': np.arange(.1, 2.0, .05)\n",
    "    },\n",
    "    'kNN': {\n",
    "        'n_neighbors': range(2, 15)\n",
    "    }\n",
    "}\n",
    "\n",
    "classifiers = [\n",
    "    ('SVM/C', svm.SVC),\n",
    "    ('kNN', KNeighborsClassifier)\n",
    "]\n",
    "\n",
    "results = search(classifiers, options, datasets, .20, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are able to save the automation results in a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results).sort_values(['score'], ascending=[False])\n",
    "results_df['rank'] = pd.Series(range(1, len(results_df) + 1), index=results_df.index)\n",
    "results_df[['rank', 'classifier', 'options', 'dataset', 'score']].to_csv('../classifiers/results_20181110151634_20_0.csv', sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix & PCA\n",
    "\n",
    "The confusion matrix shows which of our test predictions after training were (not) correct. It shows the amount of labels predicted as a certain label for every label.\n",
    "\n",
    "We also tested using Principal Component Analysis, but we can not consistently increase the accuracy. If we found a good value to use in the PCA constructor depending on the train test split sometimes the accuracy increases, somethimes it decreases. So, we decided to not use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9921875\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best = svm.SVC(kernel='rbf', C=3.65, gamma=0.1)\n",
    "X_train, X_test, Y_train, Y_test = split(scaled_v8, .20, 3)\n",
    "\n",
    "# pca = PCA(.98)\n",
    "# pca.fit(X_train)\n",
    "# X_train = pca.transform(X_train)\n",
    "# X_test = pca.transform(X_test)\n",
    "\n",
    "Y_pred = best.fit(X_train, Y_train).predict(X_test)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes):\n",
    "#     print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Greens)\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "\n",
    "print 'Accuracy', best.score(X_test, Y_test)\n",
    "plot_confusion_matrix(cnf_matrix, classes=range(0,10))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
